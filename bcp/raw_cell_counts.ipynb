{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f97b15a-8f62-4528-ba5a-269827a642ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from qa_mods import *\n",
    "import multiprocessing\n",
    "import h5py\n",
    "import fsspec\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "s3client = boto3.client('s3')\n",
    "paginator = s3client.get_paginator('list_objects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d189f7-d610-4bfe-9922-70368be3eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose data source: 'manifest' or 's3'\n",
    "data_source = ''\n",
    "\n",
    "# === Common parameters (needed for both modes) ===\n",
    "order = ''      # Needed for output file naming\n",
    "\n",
    "# === Parameters for 's3' mode only ===\n",
    "provider = ''  # psomagen, novogene\n",
    "proj = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4deeef-e486-4ea3-83e8-367c2555d62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_raw_filtered(bucket_name, prefix):\n",
    "    \"\"\"\n",
    "    Given a bucket and prefix, go through s3 directory and find all files ending with suffix\n",
    "    If there are no uris that have \"per_sample_outs\", can assume that this was not run with \"multi\" and can use all filtered_feature_bc_matrix.h5\n",
    "    \"\"\"\n",
    "    suffix = 'filtered_feature_bc_matrix.h5'\n",
    "    \n",
    "    # Use a paginator to handle cases with more than 1000 objects\n",
    "    paginator = s3client.get_paginator('list_objects_v2')\n",
    "    \n",
    "    # List objects with the specified prefix\n",
    "    pages = paginator.paginate(Bucket=bucket_name, Prefix=prefix)\n",
    "    \n",
    "    matching_files = []\n",
    "    all_keys = []\n",
    "    for page in pages:\n",
    "        if 'Contents' in page:\n",
    "            for obj in page['Contents']:\n",
    "                # Filter client-side for the specific suffix\n",
    "                if obj['Key'].endswith(suffix):\n",
    "                    all_keys.append(obj['Key'])\n",
    "                \n",
    "    if len([i for i in all_keys if re.search('per_sample_outs',i)])>0:\n",
    "        matching_files = [i for i in all_keys if re.search('per_sample_outs',i)]\n",
    "    else:\n",
    "        matching_files = all_keys\n",
    "    return matching_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa52d67-382f-4248-9e2e-a1866c5080cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gather raw filtered h5 cellranger output files\n",
    "\n",
    "bucket = f'czi-{provider}'\n",
    "order_dir = f'{proj}/{order}/'\n",
    "r_order = s3client.list_objects(Bucket=bucket, Prefix=order_dir, Delimiter='/')\n",
    "all_raw_h5 = []\n",
    "\n",
    "if 'CommonPrefixes' in r_order:\n",
    "    groups = [e['Prefix'] for e in r_order['CommonPrefixes']]\n",
    "    for g in groups:\n",
    "        matching_files = find_raw_filtered(bucket, g)\n",
    "        all_raw_h5.extend(matching_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d642ad9-6325-436c-9eb9-d88ba5af03e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do a sanity check and review raw filtered h5 files that will be counted\n",
    "\n",
    "all_raw_h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012daf5d-544e-4542-9c0f-ec4481852b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw_filtered(s3_uri):\n",
    "    \"\"\"\n",
    "    Opens an H5 file directly from S3 using fsspec and h5py, \n",
    "    reading only the necessary metadata bytes to get the shape.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f'Accessing metadata for {s3_uri}')\n",
    "\n",
    "        cell_count = 0\n",
    "        with fsspec.open(s3_uri, 'rb') as f:\n",
    "            with h5py.File(f, 'r') as h5:\n",
    "                cell_count = h5['matrix']['barcodes'].shape[0]\n",
    "\n",
    "        return {\n",
    "            'uri': clean_uri(s3_uri),\n",
    "            'observations_cells': cell_count,\n",
    "            'status': 'Success'\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'[{os.getpid()}] Error processing {s3_uri}: {e}')\n",
    "        return {\n",
    "            'uri': clean_uri(s3_uri),\n",
    "            'observations_cells': 0,\n",
    "            'status': f'Error: {str(e)}'\n",
    "        }\n",
    "\n",
    "\n",
    "def clean_uri(s3_uri):\n",
    "    \"\"\"\n",
    "    Extract GroupID and subsample if present from URI, where non-multi will just have GroupID,\n",
    "    v9 cellranger will have 'count' subdirectory, and v10 will not have 'count' subdirectory\n",
    "    \"\"\"\n",
    "    summary_id = \"\"\n",
    "    if not re.search('per_sample_outs', s3_uri):\n",
    "        summary_id = s3_uri.split('/')[4]\n",
    "    else:\n",
    "        if s3_uri.split('/')[-2] == 'count':\n",
    "            summary_id = f'{s3_uri.split(\"/\")[5]}/{s3_uri.split(\"/\")[-3]}'\n",
    "        else:\n",
    "            summary_id = f'{s3_uri.split(\"/\")[5]}/{s3_uri.split(\"/\")[-2]}'\n",
    "            \n",
    "    return summary_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88bda97-7744-4fff-ad2d-a406617ea7c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Go through list of raw filtered h5 in parallel, adjust number of processes if many h5 files that need to be analyzed\n",
    "\n",
    "NUM_PROCESSES = 5\n",
    "\n",
    "with multiprocessing.Pool(processes=NUM_PROCESSES) as pool:\n",
    "    # pool.map distributes the s3_h5_files list to the processing function\n",
    "    # and returns a list of dictionaries (the return values from the function)\n",
    "    all_file_results = pool.map(process_raw_filtered, [f's3://{bucket}/{i}' for i in all_raw_h5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a708f66d-23a5-4eda-a7d9-7ec57661a6a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print a summary report per group and final total\n",
    "\n",
    "print('\\n--- Summary Report ---')\n",
    "total_observations = 0\n",
    "print(pd.DataFrame.from_dict(all_file_results))\n",
    "for result in all_file_results:\n",
    "    total_observations += result['observations_cells']\n",
    "\n",
    "print(f'\\nTotal observations across all files: {total_observations}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ca25d-36ae-494b-89e0-fd3e03988985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
