{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca26c9b-632f-4bed-a4bd-06b89cecf937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import tarfile\n",
    "from cellxgene_schema.write_labels import AnnDataLabelAppender\n",
    "from urllib.parse import quote\n",
    "from cellxgene_ontology_guide.ontology_parser import OntologyParser\n",
    "ontology_parser = OntologyParser(schema_version=\"v6.0.0\")\n",
    "from cellxgene_ontology_guide.supported_versions import CXGSchema, load_supported_versions\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "s3client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f3f071-0b7c-4ef8-b7cb-49cdad9c153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(s_dir):\n",
    "    mx_h5 = f'{s_dir}/count/sample_filtered_feature_bc_matrix.h5'\n",
    "    metrics_csv = f'{s_dir}/metrics_summary.csv'\n",
    "    cri_tar = f'{s_dir}/count/crispr_analysis.tar.gz'\n",
    "    \n",
    "    for file_path in [mx_h5, metrics_csv, cri_tar]:\n",
    "        f = file_path.split('/')[-1]\n",
    "        s3client.download_file(bucket_name, file_path, f)\n",
    "\n",
    "\n",
    "def custom_var_to_obs(adata):\n",
    "    moved = []\n",
    "    for gene_index in adata.var[\n",
    "        (adata.var['feature_types'] == 'Gene Expression') &\n",
    "        (adata.var['gene_ids'].str.startswith('ENS') == False)\n",
    "    ].index:\n",
    "        gene_id = adata.var.loc[gene_index]['gene_ids']\n",
    "        gene_values = adata.X[:, adata.var.index.get_loc(gene_index)]\n",
    "        adata.obs[gene_id] = gene_values.A.flatten() if hasattr(gene_values, 'A') else gene_values.toarray().flatten().tolist()\n",
    "        moved.append(gene_id)\n",
    "\n",
    "    adata.var.set_index('gene_ids', inplace=True)\n",
    "    var_to_keep = [i for i in adata.var.index if i not in moved]\n",
    "    adata = adata[:, var_to_keep]\n",
    "    adata.var = adata.var.replace('', np.nan).dropna(axis=1, how='all')\n",
    "\n",
    "    return adata\n",
    "\n",
    "\n",
    "def gather_crispr():\n",
    "    '''\n",
    "    obtain guide assignement from 10x cellranger output files\n",
    "    currently will update 1-Jun and 2-Jun to JUN-1 and JUN-2, respectively\n",
    "\n",
    "    return df: dataframe containing crispr guide calling\n",
    "    '''\n",
    "    tar = tarfile.open('crispr_analysis.tar.gz', 'r:gz')\n",
    "    f = tar.extractfile('protospacer_calls_per_cell.csv')\n",
    "    df = pd.read_csv(f).rename(columns={'num_umis':'num_umis_guide_id'})\n",
    "    tar.close()\n",
    "    df['genetic_perturbation_guide_id'] = df['feature_call'].apply(lambda x: x.replace('|',' || '))\n",
    "    df['genetic_perturbation_guide_id'] = df['genetic_perturbation_guide_id'].str.replace('1-Jun', 'JUN-1')\n",
    "    df['genetic_perturbation_guide_id'] = df['genetic_perturbation_guide_id'].str.replace('2-Jun', 'JUN-2')\n",
    "    df = df[['cell_barcode','genetic_perturbation_guide_id','num_umis_guide_id']].set_index('cell_barcode')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def gather_metrics(samp):\n",
    "    df = pd.read_csv('metrics_summary.csv')\n",
    "    df['Metric'] = df.apply(lambda x: f\"{x['Metric Name']}, {x['Library Type']}, {x['Category'].replace('Cells','Sample')}\", axis=1)\n",
    "\n",
    "    probe_barcodes = ' || '.join(df[\n",
    "        (df['Metric Name'] == 'Sample ID') &\n",
    "        (df['Metric Value'] == samp)\n",
    "    ]['Group Name'].unique())\n",
    "\n",
    "    df = df[\n",
    "        (df['Grouped By'].isin(['Fastq ID','Probe barcode ID']) == False) &\n",
    "        (df['Category'].isin(['Library','Cells']))\n",
    "    ]\n",
    "    df = df[['Metric','Metric Value']].set_index('Metric').transpose()\n",
    "\n",
    "    for c in df.columns:\n",
    "        v = df[c].iloc[0]\n",
    "        if v.endswith('%'):\n",
    "            df[c] = df[c].apply(lambda x: float(x.rstrip('%')) / 100)\n",
    "        elif '%' in v:\n",
    "            df.drop(columns=c, inplace=True)\n",
    "        else:\n",
    "            df[c] = df[c].apply(lambda x: int(x.replace(',','')))\n",
    "\n",
    "    df['Probe barcode IDs'] = probe_barcodes\n",
    "\n",
    "    keep = {\n",
    "        'Confidently mapped reads in cells, Gene Expression, Sample': 'fraction_mapped_reads_in_cells_gex',\n",
    "        'Median genes per cell, Gene Expression, Sample': 'median_genes_per_cell',\n",
    "        'Cells, CRISPR Guide Capture, Sample': 'cell_count_cri',\n",
    "        'Cells, Gene Expression, Sample': 'cell_count_gex',\n",
    "        'Valid GEM barcodes, CRISPR Guide Capture, Library': 'fraction_valid_barcodes_cri',\n",
    "        'Valid GEM barcodes, Gene Expression, Library': 'fraction_valid_barcodes_gex',\n",
    "        'Reads confidently mapped to probe set, Gene Expression, Sample': 'frac_reads_mapped_gex',\n",
    "        'Confidently mapped to genome, Gene Expression, Library': 'frac_reads_mapped_gex',\n",
    "        'Mean reads per cell, Gene Expression, Sample': 'mean_reads_per_cell_gex'\n",
    "    }\n",
    "\n",
    "    df = df[[f for f in keep.keys() if f in df.columns]].rename(columns=keep)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def cxg_add_labels(adata):\n",
    "    adata.obs['cell_type_ontology_term_id'] = 'unknown'\n",
    "    labeler = AnnDataLabelAppender(adata)\n",
    "    labeler._add_labels()\n",
    "    adata.obs.drop(columns=['cell_type_ontology_term_id','cell_type'],inplace=True)\n",
    "\n",
    "    schema_v = labeler.schema_version\n",
    "    adata.uns['schema_version'] = schema_v\n",
    "    adata.uns['schema_reference'] = labeler._build_schema_reference_url(schema_v)\n",
    "\n",
    "\n",
    "def add_guide_metadata(adata, sheet, guide_gid):\n",
    "    '''\n",
    "    Add guide metadata into adata.uns from Lattice wrangling sheet\n",
    "    \n",
    "    :param obj adata: the anndata object that is being transformed into the curated matrix\n",
    "    :param obj guide_df: the dataframe containing guide metadata from wrangling sheet\n",
    "    \n",
    "    :returns obj adata: modified adata to contain guide metadata\n",
    "    '''\n",
    "    url = f'https://docs.google.com/spreadsheets/d/{sheet}/export?format=csv&gid={guide_gid}'\n",
    "    response = requests.get(url)\n",
    "    guide_df = pd.read_csv(BytesIO(response.content), comment=\"#\", dtype=str)\n",
    "    genetic_perturbations = {}\n",
    "    \n",
    "    for row in guide_df.itertuples():\n",
    "        genetic_perturbations[row.guide_id] = {}\n",
    "        genetic_perturbations[row.guide_id]['role'] = 'targeting' if row.guide_role == 'Targeting a Gene' else 'control'\n",
    "        genetic_perturbations[row.guide_id]['protospacer_sequence'] = row.guide_protospacer\n",
    "        genetic_perturbations[row.guide_id]['protospacer_adjacent_motif'] = row.guide_PAM\n",
    "        genetic_perturbations[row.guide_id]['target_genomic_regions'] = [str(row.chromosome).replace(\"chr\",\"\") +\n",
    "                                                                         \":\" + str(row.start) +\n",
    "                                                                         \":\" + str(row.end) + \n",
    "                                                                         \":\" + str(row.strand)]\n",
    "        if not pd.isna(row.overlapping_gene_ids):\n",
    "            genetic_perturbations[row.guide_id]['target_features'] = {}\n",
    "            for i in range(len(row.overlapping_gene_ids.split(\";\"))):\n",
    "                genetic_perturbations[row.guide_id]['target_features'][row.overlapping_gene_ids.split(\";\")[i]] = row.overlapping_gene_names.split(\";\")[i]\n",
    "                                                                             \n",
    "            \n",
    "    adata.uns['genetic_perturbations'] = genetic_perturbations\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def determine_perturbation_strategy(adata):\n",
    "    '''\n",
    "    Assess feature_call from protospacer_calls_per_cell.csv, where if all guides\n",
    "    assigned to a single cell are all control, then 'control'. Otherwise, it is \"no perturbations\"\n",
    "    if no guids or one of the following if targeting:\n",
    "        - \"CRISPR activation screen\"\n",
    "        - \"CRISPR interference screen\"\n",
    "        - \"CRISPR knockout mutant\"\n",
    "        - \"CRISPR knockout screen\"\n",
    "    \n",
    "    :param obj adata: the anndata object that is being transformed into the curated matrix\n",
    "\n",
    "    :returns obj adata: modified adata to contain perturbation_strategy as cell metadata\n",
    "    '''\n",
    "    adata.obs['genetic_perturbation_strategy_calculated'] = adata.obs['genetic_perturbation_guide_id']\n",
    "    adata.obs['genetic_perturbation_strategy_calculated'] = adata.obs['genetic_perturbation_strategy_calculated'].apply(\n",
    "        lambda x: x.split(' || ') if pd.notna(x) else 'no perturbations'\n",
    "    )\n",
    "    adata.obs['genetic_perturbation_strategy_calculated'] = adata.obs['genetic_perturbation_strategy_calculated'].apply(\n",
    "        lambda x: [adata.uns['genetic_perturbations'][i]['role'] for i in x] if isinstance(x, list)\n",
    "            else x        \n",
    "    )\n",
    "    adata.obs['genetic_perturbation_strategy_calculated'] = adata.obs['genetic_perturbation_strategy_calculated'].apply(\n",
    "         lambda x: 'control' if isinstance(x, list) and 'targeting' not in set(x)\n",
    "            else x\n",
    "    )\n",
    "    adata.obs.loc[adata.obs['genetic_perturbation_strategy_calculated']=='control', 'genetic_perturbation_strategy'] = 'control'\n",
    "    adata.obs.loc[adata.obs['genetic_perturbation_strategy_calculated']=='no perturbations', 'genetic_perturbation_strategy'] = 'no perturbations'\n",
    "    adata.obs.drop(columns=['genetic_perturbation_strategy_calculated'], inplace=True)\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def add_library_id(adata, sheet_id, pooled_gid, sample):\n",
    "    '''\n",
    "    load in pooled library template and determine which library \"pool_name\" that this subsample was derived from.\n",
    "    This is specific to 10x assays, and will have to be re-evaluated for plate assays\n",
    "\n",
    "    :param obj adata: the anndata object that is being transformed into the curated matrix\n",
    "    :param str sheet_id: the gid of the google sheet for the wrangling template\n",
    "    :param str pooled_gid: the gid of the google sheet template tab for \"pooled library template\"\n",
    "    :param str sample: the sampleID of this subsample\n",
    "\n",
    "    :returns obj adata: modified adata that contains library idenfier\n",
    "    '''\n",
    "    url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={pooled_gid}'\n",
    "    pooled_df = pd.read_csv(url, comment='#', index_col=False).dropna(axis=1, how='all')\n",
    "    library_id = pooled_df.loc[(pooled_df['sample_name'] == sample) & (pooled_df['library type']=='GEX'), 'pool_name'][0]\n",
    "    adata.obs['library_name'] = library_id\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca356f-0b0c-48cb-9ced-bc50f06f0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the sample metadata\n",
    "sheet = '1YVhCswWQD6YsC_oqLCejzseraW_Xxi6BUp1_MXOsUII'\n",
    "gid = '1236594312'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet}/export?format=csv&gid={gid}'\n",
    "response = requests.get(url)\n",
    "sample_df = pd.read_csv(BytesIO(response.content), comment=\"#\", dtype=str).dropna(axis=1,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfef2216-6069-401e-b506-a2263164bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping ontologies\n",
    "\n",
    "col_ont_map = {\n",
    "    'organism':'NCBITaxon',\n",
    "    'sex':'PATO',\n",
    "    'self_reported_ethnicity':'HANCESTRO',\n",
    "    'disease':'MONDO',\n",
    "    'assay':'EFO',\n",
    "    'development_stage':{'NCBITaxon:6239':'WBls', # C. Elegans\n",
    "                         'NCBITaxon:7227':'FBdv', # Drosophila\n",
    "                         'NCBITaxon:10090':'MmusDv', # Mouse\n",
    "                         'NCBITaxon:7955':'ZFS', # Zebrafish\n",
    "                         'other':'HsapDv' # For all other organisms, use HsapDv\n",
    "                        },\n",
    "    'tissue':{'NCBITaxon:6239':'WBbt', # C. Elegans\n",
    "              'NCBITaxon:7227':'FBbt', # Drosophila\n",
    "              'NCBITaxon:7955':'ZFA', # Zebrafish\n",
    "              'other':'UBERON' # For all other organisms, use UBERON\n",
    "             }\n",
    "}\n",
    "\n",
    "\n",
    "for col in col_ont_map:\n",
    "    map_dict = {}\n",
    "    for label in sample_df[col].unique():\n",
    "        if col == 'disease' and label == 'normal': # normal is not in MONDO ontology\n",
    "            map_dict[label] = 'PATO:0000461'\n",
    "        elif label in ['unknown','n/a']: # unknown and n/a won't be in ontologies, pass along\n",
    "            map_dict[label] = label\n",
    "        elif col in ['tissue','development_stage']:\n",
    "            if col == 'tissue':\n",
    "                # Find what tissue type is at label row\n",
    "                if sample_df.loc[sample_df[col] == label, 'tissue_type'].tolist()[0] != 'tissue':\n",
    "                    map_dict[label] = label # Don't map cell type in tissue\n",
    "                    continue\n",
    "            # Find what organism term id is at label row\n",
    "            org_term_id = sample_df.loc[sample_df[col] == label, 'organism_ontology_term_id'].tolist()[0]\n",
    "            if org_term_id in col_ont_map[col]:\n",
    "                # Get ontology of specific organism and map label\n",
    "                species_ont = col_ont_map[col][sample_df.loc[org_term_id]]\n",
    "                term_id = ontology_parser.get_term_id_by_label(label, species_ont)\n",
    "            else:\n",
    "                term_id = ontology_parser.get_term_id_by_label(label, col_ont_map[col]['other'])\n",
    "        else:\n",
    "            term_id = ontology_parser.get_term_id_by_label(label, col_ont_map[col])\n",
    "        if term_id == None:\n",
    "            print(f\"Matching '{col_ont_map[col]}' term id not found for label '{label}' in column '{col}'\")\n",
    "        map_dict[label] = term_id\n",
    "    sample_df[col + '_ontology_term_id'] = sample_df[col].map(map_dict)\n",
    "    del sample_df[col]\n",
    "    \n",
    "# Blank fields in worksheet result in NaN values in dataframe, replacing these with n/a ? \n",
    "# Could also replace with unknown for certain columns using fillna options?\n",
    "sample_df.fillna('n/a', inplace=True)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6914a64-c8dd-4866-8a57-c7ca0f8746e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'czi-psomagen'\n",
    "lab = 'marson'\n",
    "proj = 'mapping-grns-perturb-seq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78fdbfc-45b7-4069-a300-09aeb813f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dir = f'{lab}-{proj}/'\n",
    "r = s3client.list_objects(Bucket=bucket_name, Prefix=my_dir, Delimiter='/')\n",
    "orders = [o['Prefix'].replace(my_dir,'') for o in r['CommonPrefixes']]\n",
    "\n",
    "samples = []\n",
    "for o in orders:\n",
    "    r = s3client.list_objects(Bucket=bucket_name, Prefix=f'{my_dir}{o}', Delimiter='/')\n",
    "    libs = [l['Prefix'].replace(f'{my_dir}{o}','') for l in r['CommonPrefixes']]\n",
    "    for l in libs:\n",
    "        r = s3client.list_objects(Bucket=bucket_name, Prefix=f'{my_dir}{o}{l}processed/cellranger/', Delimiter='/')\n",
    "        dates = [d['Prefix'].replace(f'{my_dir}{o}{l}processed/cellranger/','') for d in r['CommonPrefixes']]\n",
    "        for d in dates:\n",
    "            r = s3client.list_objects(Bucket=bucket_name, Prefix=f'{my_dir}{o}{l}processed/cellranger/{d}outs/per_sample_outs/', Delimiter='/')\n",
    "            subs = [s['Prefix'].replace(f'{my_dir}{o}{l}processed/cellranger/{d}outs/per_sample_outs/','') for s in r['CommonPrefixes']]\n",
    "            for s in subs:\n",
    "                samples.append({\n",
    "                    'order': o,\n",
    "                    'library': l.rstrip('/'),\n",
    "                    'date': d,\n",
    "                    'sample': s.rstrip('/')\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff24c2b5-49db-4f56-b6d1-afe038409ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify which sample to curate\n",
    "n = 0\n",
    "s = samples[n]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d329fa-62b9-49da-aedb-c844aec6407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = s['order']\n",
    "lib = s['library']\n",
    "run_date = s['date']\n",
    "samp = s['sample']\n",
    "\n",
    "### Download and read in h5 file\n",
    "s_dir = f'{lab}-{proj}/{order}{lib}/processed/cellranger/{run_date}outs/per_sample_outs/{samp}'\n",
    "download_files(s_dir)\n",
    "adata = sc.read_10x_h5('sample_filtered_feature_bc_matrix.h5', gex_only=True)\n",
    "\n",
    "### Track additional tab gids from Lattice wrangling sheet\n",
    "guide_gid = \"1589848458\"\n",
    "pooled_gid = \"2009719915\"\n",
    "\n",
    "adata = custom_var_to_obs(adata)\n",
    "adata = add_library_id(adata, sheet, pooled_gid, samp)\n",
    "\n",
    "adata.obs['lab'] = lab\n",
    "adata.obs['project'] = proj\n",
    "adata.obs['sample_name'] = samp\n",
    "\n",
    "adata.obs = adata.obs.merge(sample_df, on='sample_name', how='left').set_index(adata.obs.index)\n",
    "adata.uns['organism_ontology_term_id'] = adata.obs['organism_ontology_term_id'].unique()[0]\n",
    "adata.obs.drop(columns=['organism_ontology_term_id'],inplace=True)\n",
    "\n",
    "crispr_df = gather_crispr()\n",
    "adata.obs = adata.obs.merge(\n",
    "    crispr_df, left_index=True, right_index=True, how='left'\n",
    ").set_index(adata.obs.index)\n",
    "\n",
    "metrics_df = gather_metrics(samp)\n",
    "for c in metrics_df.columns:\n",
    "    adata.obs[c] = metrics_df[c].values[0]\n",
    "\n",
    "cxg_add_labels(adata)\n",
    "\n",
    "### Startswith('mt-') works for human & mouse, more attn needed for other organisms\n",
    "adata.var['mt'] = adata.var['feature_name'].str.lower().str.startswith('mt-')\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], inplace=True)\n",
    "\n",
    "### Add guide schema metadata to adata.uns and adata.obs\n",
    "adata = add_guide_metadata(adata, sheet, guide_gid)\n",
    "adata = determine_perturbation_strategy(adata)\n",
    "\n",
    "adata.write(filename=f'{samp}_curated.h5ad', compression='gzip')\n",
    "\n",
    "for f in ['sample_filtered_feature_bc_matrix.h5','crispr_analysis.tar.gz','metrics_summary.csv']:\n",
    "    os.remove(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
