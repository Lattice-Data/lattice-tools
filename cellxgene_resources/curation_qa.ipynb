{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook provides quality assurance, much of which cannot be covered by cellxgene validate, of AnnData objects towards CELLxGENE curation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import scanpy as sc\n",
    "import subprocess\n",
    "from random import randint\n",
    "from scipy import sparse\n",
    "from urllib.parse import quote\n",
    "\n",
    "\n",
    "portal_obs_fields = [\n",
    "    'assay',\n",
    "    'cell_type',\n",
    "    'development_stage',\n",
    "    'disease',\n",
    "    'self_reported_ethnicity',\n",
    "    'organism',\n",
    "    'sex',\n",
    "    'tissue'\n",
    "]\n",
    "\n",
    "curator_obs_fields = [e + '_ontology_term_id' for e in portal_obs_fields] + ['donor_id','suspension_type','tissue_type','is_primary_data']\n",
    "full_obs_standards = portal_obs_fields + curator_obs_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the AnnData object\n",
    "**Update the path of the file**<br>\n",
    "*The sample `valid.h5ad` that is in this repo is subsampled from https://cellxgene.cziscience.com/e/f15e263b-6544-46cb-a46e-e33ab7ce8347.cxg/ with some metadata alterations for the purpose of this notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'valid.h5ad'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the AnnData object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(file)\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data layers\n",
    "**Check if any matrix should be stored as sparse format but isn't**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_sparsity(x):\n",
    "    if isinstance(x, sparse.coo_matrix) or isinstance(x, sparse.csr_matrix) or isinstance(x, sparse.csc_matrix):\n",
    "        sparsity = 1 - x.count_nonzero() / float(np.cumprod(x.shape)[-1])\n",
    "    elif isinstance(x, np.ndarray):\n",
    "        sparsity = 1 - np.count_nonzero(x) / float(np.cumprod(x.shape)[-1])\n",
    "    else:\n",
    "        print(f'matrix is of type {type(x)}, sparsity calculation has not been implemented')\n",
    "\n",
    "    return sparsity\n",
    "\n",
    "\n",
    "max_sparsity = 0.5\n",
    "\n",
    "sparsity = determine_sparsity(adata.X)\n",
    "print(f'X sparsity: {sparsity}')\n",
    "if sparsity > max_sparsity and type(adata.X) != sparse.csr_matrix:\n",
    "    print('WARNING: X should be converted to sparse')\n",
    "\n",
    "if adata.raw:\n",
    "    sparsity = determine_sparsity(adata.raw.X)\n",
    "    print(f'raw.X sparsity: {sparsity}')\n",
    "    if sparsity > max_sparsity and type(adata.raw.X) != sparse.csr_matrix:\n",
    "        print('WARNING: raw.X should be converted to sparse')\n",
    "\n",
    "for l in adata.layers:\n",
    "    sparsity = determine_sparsity(adata.layers[l])\n",
    "    print(f'layers[{l}] sparsity: {sparsity}')\n",
    "    if sparsity > max_sparsity and type(adata.layers[l]) != sparse.csr_matrix:\n",
    "        print(f'WARNING: layers[{l}] should be converted to sparse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the min/max of each layer**<br>\n",
    "*Look for duplicated or other unnecessary layers*<br>\n",
    "*Raw should be whole, positive, ~10<sup>3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if adata.raw:\n",
    "    print('raw min = ' + str(adata.raw.X.min()))\n",
    "    print('raw max = ' + str(adata.raw.X.max()))\n",
    "    non_integer = np.any(~np.equal(np.mod(adata.raw.X.data, 1), 0))\n",
    "else:\n",
    "    non_integer = np.any(~np.equal(np.mod(adata.X.data, 1), 0))\n",
    "\n",
    "if non_integer == False:\n",
    "    print('raw is all integers')\n",
    "else:\n",
    "    print('ERROR: raw contains non-integer values')\n",
    "\n",
    "print('X min = ' + str(adata.X.min()))\n",
    "print('X max = ' + str(adata.X.max()))\n",
    "\n",
    "for l in adata.layers:\n",
    "    print(f'layers[{l}] min = ' + str(adata.layers[l].min()))\n",
    "    print(f'layers[{l}] max = ' + str(adata.layers[l].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obsm\n",
    "**Confirm at least one set of embeddings is present**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View embeddings to identify which matches paper figures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellpop_field = 'cell_type'\n",
    "\n",
    "if f'{cellpop_field}_colors' in adata.uns:\n",
    "    remove_colors = False\n",
    "else:\n",
    "    remove_colors = True\n",
    "\n",
    "sc.set_figure_params(dpi=100)\n",
    "for e in adata.obsm:\n",
    "    sc.pl.embedding(adata, basis=e, color=cellpop_field, legend_loc='on data')\n",
    "if remove_colors:\n",
    "    del adata.uns[f'{cellpop_field}_colors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check that the default_embedding value, if defined, is in obsm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'default_embedding' in adata.uns:\n",
    "    de = adata.uns['default_embedding']\n",
    "    if de not in adata.obsm_keys():\n",
    "        print('ERROR:' + de + ' not in ' + ','.join(adata.obsm_keys()))\n",
    "    else:\n",
    "        print(de + ' is in ' + ','.join(adata.obsm_keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# uns\n",
    "**Check for uns schema fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns.get('title','ERROR: title missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confirm `schema_version` not in uns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns.get('schema_version')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Browse all of uns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *_colors\n",
    "**scanpy & cellxgene allow for specification of cluster colors when coloring by specific obs fields**<br>\n",
    "**A list of color codes is specified in `uns.PROP_colors` where `PROP` is an obs field**<br>\n",
    "**The number of color codes in `uns.PROP_colors` must be at least as long as the number of unique values in `obs.PROP`**<br>\n",
    "<br>\n",
    "**Check for _colors fields & ensure each matches a categorical obs field**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numb_types = ['int_', 'int8', 'int16', 'int32', 'int64', 'uint8', 'uint16', 'uint32', 'uint64','float_', 'float16', 'float32', 'float64']\n",
    "\n",
    "for k in adata.uns.keys():\n",
    "    if k.endswith('_colors'):\n",
    "        colors = len(adata.uns[k])\n",
    "        obs_field = k[:-(len('_colors'))]\n",
    "\n",
    "        if obs_field in portal_obs_fields:\n",
    "            print(f'ERROR: consider copying uns.{k} to uns.{obs_field}_ontology_term_id_colors so palette transfers to CxG viz')\n",
    "        elif obs_field not in adata.obs.keys():\n",
    "            print(f'ERROR: {obs_field} not found in obs, consider DELETING or RENAMING uns.{k}')\n",
    "        else:\n",
    "            values = len(adata.obs[obs_field].unique())\n",
    "            if colors < values:\n",
    "                print(f'ERROR: uns.{k} has only {str(colors)} colors but obs.{obs_field} has {str(values)} values')\n",
    "            if adata.obs.dtypes[obs_field].name in numb_types:\n",
    "                print(f'ERROR: uns.{k} is associated with non-categorical {obs_field}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensure schema fields are present and values are valid & precise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in curator_obs_fields:\n",
    "    print(o)\n",
    "    if o not in adata.obs_keys():\n",
    "        print('NOT IN OBS')\n",
    "    else:\n",
    "        un = adata.obs[o].unique()\n",
    "        if un.dtype == 'category':\n",
    "            print(un.to_list())\n",
    "        else:\n",
    "            print(un.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensure the portal fields are not used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in portal_obs_fields:\n",
    "    print(o)\n",
    "    if o not in adata.obs_keys():\n",
    "        print('NOT IN OBS')\n",
    "    else:\n",
    "        un = adata.obs[o].unique()\n",
    "        if un.dtype == 'category':\n",
    "            print(un.to_list())\n",
    "        else:\n",
    "            print(un.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10x barcode checker\n",
    "**Checks a random selection of the barcodes against 10x barcode lists**<br>\n",
    "*Can help confirm 3' v2 vs v3 vs multiome*<br>\n",
    "*5' v1 and v2 kits use the same barcode list as 3' v2*<br>\n",
    "*Assumes the barcode is in the index. Suffixes/prefixes are OK*<br>\n",
    "*The barcode list files are in this repo in ref_files/ (the v3 file will need to be unzipped)*<br>\n",
    "<br>\n",
    "**Define the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TENx_barcode_checker(ref_df, obs_df, num_to_check):\n",
    "    obs_df_sample = obs_df.sample(num_to_check, axis=0) # can add random_state=1 for reproducibility\n",
    "    obs_df_split = obs_df_sample.index.str.split('([ACTG]{16})')\n",
    "    barcodes = pd.DataFrame([b for l in obs_df_split for b in l if re.match(r\".*[ACTG]{16}.*\", b)])    \n",
    "    if barcodes.empty:\n",
    "        return pd.DataFrame({'summary':['no barcode'] * num_to_check})\n",
    "    else:\n",
    "        barcodes.rename(columns={0:'barcode'},inplace=True)\n",
    "        barcodes.set_index('barcode', inplace=True)\n",
    "        barcode_results = barcodes.merge(ref_df,on='barcode',how='left')\n",
    "        barcode_results.fillna(0, inplace=True)\n",
    "        barcode_results['summary'].replace(0, None, inplace=True)\n",
    "        return barcode_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define `prop` and 20% of the barcodes will be checked for each unique value in `obs.prop`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = 'assay'\n",
    "\n",
    "results = []\n",
    "csv = 'ref_files/10X_barcode_table.csv.gz'\n",
    "ref_df = pd.read_csv(csv, sep=',', header=0, index_col='barcode')\n",
    "\n",
    "for a in adata.obs[prop].unique():\n",
    "    obs_df = adata.obs[adata.obs[prop] == a]\n",
    "    num_to_check = obs_df.shape[0]  # default is check 20% of barcodes; Note: there may be low numbers of barcodes associated with a prop, num_to_check will be 0 if floor divisor is present!\n",
    "    r = TENx_barcode_checker(ref_df, obs_df, num_to_check)\n",
    "    r_dict = {'3pv2_5pv1_5pv2': None, '3pv3': None, 'multiome': None,'multiple': None, 'None': None} | r['summary'].value_counts().to_dict()\n",
    "    r_dict[prop] = a\n",
    "    results.append(r_dict)\n",
    "\n",
    "pd.DataFrame(results).set_index(prop).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look for general obs field issues and collect obs information to check for redundant information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_fields = []\n",
    "gradient_fields = []\n",
    "uber_dict = {}\n",
    "for o in adata.obs.keys():\n",
    "    vc_dict = adata.obs[o].value_counts(dropna=False).to_dict()\n",
    "    counts = '_'.join([str(c) for c in vc_dict.values()])\n",
    "    count_len = len(vc_dict.keys())\n",
    "    values = [str(i) for i in vc_dict.keys()]\n",
    "\n",
    "    if o.startswith(' ') or o.endswith(' ') or '  ' in o:\n",
    "        print('leading/trailing whitespace:' + o)\n",
    "\n",
    "    if o not in full_obs_standards and ' '.join(o.split()).lower() in full_obs_standards:\n",
    "        print('schema conflict:' + o)\n",
    "\n",
    "    if count_len == 1:\n",
    "        lone_v = str(list(vc_dict.keys())[0])\n",
    "        if o not in full_obs_standards:\n",
    "            print('all same value:' + o + ',' + lone_v)\n",
    "\n",
    "    numb_types = ['int_', 'int8', 'int16', 'int32', 'int64', 'uint8', 'uint16', 'uint32', 'uint64','float_', 'float16', 'float32', 'float64']\n",
    "    if adata.obs.dtypes[o].name in numb_types:\n",
    "        gradient_fields.append(o)\n",
    "    else:\n",
    "        #check for long categories as they will not be enabled for coloring\n",
    "        if count_len > 200 and o != 'observation_joinid':\n",
    "            long_fields.append(o)\n",
    "\n",
    "        #report value_counts to later look for redundancy\n",
    "        metadata = {\n",
    "            'values': values,\n",
    "            'property': o\n",
    "        }\n",
    "        if counts in uber_dict:\n",
    "            uber_dict[counts].append(metadata)\n",
    "        else:\n",
    "            uber_dict[counts] = [metadata]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comb value_counts to report possible redundancy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in uber_dict.items():\n",
    "    if '_' in k and not k.startswith('1_1'):\n",
    "        props = [e['property'] for e in v]\n",
    "        if len(v) > 1 and not all(elem in full_obs_standards for elem in props):\n",
    "            print('cells breakdown: ' + k)\n",
    "            for e in v:\n",
    "                print(e['property'])\n",
    "                #print(e['values'])\n",
    "            print('----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate any fields that may be redundant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[['development_stage_ontology_term_id','age']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for fields that aren't appropriate as gradient (e.g. cluster number)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List any categorical fields with more than 200 categories as they may not be useful in the visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See if any donors have variable donor-level metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_fields = ['donor_id',\n",
    "                'sex_ontology_term_id',\n",
    "                'development_stage_ontology_term_id',\n",
    "                'self_reported_ethnicity_ontology_term_id',\n",
    "                'disease_ontology_term_id']\n",
    "\n",
    "donor_df = pd.DataFrame(adata.obs[donor_fields].value_counts())\n",
    "donor_df = donor_df.reset_index()\n",
    "donor_df[donor_df.duplicated(subset='donor_id', keep=False) == True].sort_values('donor_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Browse the per donor metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flag any donors that are curated to a development_stage term that is deprecated**<br>\n",
    "These need to also be annotated to the latest ontology version and that mapping provided separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deprecated_dev = [\n",
    "    'HsapDv:0000004','HsapDv:0000082','HsapDv:0000235','HsapDv:0000080','HsapDv:0000174','HsapDv:0000256','HsapDv:0000083',\n",
    "    'HsapDv:0000084','HsapDv:0000081','HsapDv:0000085','HsapDv:0000236','HsapDv:0000086','HsapDv:0000204','HsapDv:0000089',\n",
    "    'HsapDv:0000088','HsapDv:0000087','HsapDv:0000090','HsapDv:0000092','HsapDv:0000091','HsapDv:0000094','HsapDv:0000093',\n",
    "    'MmusDv:0000016','MmusDv:0000030','MmusDv:0000037','MmusDv:0000038','MmusDv:0000039','MmusDv:0000040','MmusDv:0000041',\n",
    "    'MmusDv:0000044','MmusDv:0000045','MmusDv:0000046','MmusDv:0000047','MmusDv:0000048','MmusDv:0000049','MmusDv:0000050',\n",
    "    'MmusDv:0000051','MmusDv:0000052','MmusDv:0000053','MmusDv:0000054','MmusDv:0000055','MmusDv:0000056','MmusDv:0000057',\n",
    "    'MmusDv:0000058','MmusDv:0000059','MmusDv:0000061','MmusDv:0000065','MmusDv:0000066','MmusDv:0000067','MmusDv:0000068',\n",
    "    'MmusDv:0000070','MmusDv:0000071','MmusDv:0000072','MmusDv:0000073','MmusDv:0000074','MmusDv:0000075','MmusDv:0000076',\n",
    "    'MmusDv:0000096','MmusDv:0000097','MmusDv:0000098','MmusDv:0000099','MmusDv:0000100','MmusDv:0000101','MmusDv:0000102'\n",
    "]\n",
    "\n",
    "auto_migrate = {\n",
    "\t'HsapDv:0000004': 'HsapDv:0000005','HsapDv:0000235': 'HsapDv:0000264','HsapDv:0000080': 'HsapDv:0000264',\n",
    "    'HsapDv:0000174': 'HsapDv:0000273','HsapDv:0000256': 'HsapDv:0000261','HsapDv:0000081': 'HsapDv:0000264',\n",
    "    'HsapDv:0000085': 'HsapDv:0000271','HsapDv:0000087': 'HsapDv:0000258','HsapDv:0000094': 'HsapDv:0000272',\n",
    "    'HsapDv:0000093': 'HsapDv:0000227','MmusDv:0000041': 'unknown','MmusDv:0000044': 'MmusDv:0000138',\n",
    "    'MmusDv:0000045': 'MmusDv:0000140','MmusDv:0000046': 'MmusDv:0000141','MmusDv:0000049': 'MmusDv:0000150',\n",
    "    'MmusDv:0000050': 'MmusDv:0000151','MmusDv:0000051': 'MmusDv:0000152','MmusDv:0000052': 'MmusDv:0000154',\n",
    "    'MmusDv:0000053': 'MmusDv:0000155','MmusDv:0000054': 'MmusDv:0000156','MmusDv:0000055': 'MmusDv:0000157',\n",
    "    'MmusDv:0000056': 'MmusDv:0000158','MmusDv:0000057': 'MmusDv:0000159','MmusDv:0000058': 'MmusDv:0000160',\n",
    "    'MmusDv:0000059': 'MmusDv:0000161','MmusDv:0000061': 'MmusDv:0000136','MmusDv:0000065': 'MmusDv:0000162',\n",
    "    'MmusDv:0000066': 'MmusDv:0000163','MmusDv:0000067': 'MmusDv:0000164','MmusDv:0000068': 'MmusDv:0000165',\n",
    "    'MmusDv:0000070': 'MmusDv:0000166','MmusDv:0000071': 'MmusDv:0000167','MmusDv:0000072': 'MmusDv:0000168',\n",
    "    'MmusDv:0000073': 'MmusDv:0000169','MmusDv:0000074': 'MmusDv:0000170','MmusDv:0000076': 'MmusDv:0000134',\n",
    "    'MmusDv:0000096': 'MmusDv:0000138','MmusDv:0000098': 'MmusDv:0000171','MmusDv:0000099': 'MmusDv:0000172',\n",
    "    'MmusDv:0000100': 'MmusDv:0000173','MmusDv:0000101': 'MmusDv:0000174','MmusDv:0000102': 'MmusDv:0000175',\n",
    "    'MmusDv:0000113': 'MmusDv:0000177'\n",
    "}\n",
    "\n",
    "donor_df[\n",
    "    (donor_df['development_stage_ontology_term_id'].isin(deprecated_dev)) &\n",
    "    (donor_df['development_stage_ontology_term_id'].isin(auto_migrate) == False)\n",
    "    ][['donor_id','development_stage_ontology_term_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check donor sex metadata against PAR and Non-PAR genes raw expression counts**<br>\n",
    "First define functions for scRNA-seq sex analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regions_dict(par_adata,nonpar_adata,adata):\n",
    "    '''\n",
    "    Input: PAR and Non-PAR adata subsets\n",
    "    Output: dictionary containing dataframes for PAR and Non-PAR average expression counts per gene per donor\n",
    "    '''\n",
    "    region_dict = {'par': [par_adata], 'nonpar': [nonpar_adata]}\n",
    "    for k,v in region_dict.items():\n",
    "        a = v[0]\n",
    "        obs_data = pd.DataFrame(a[:, a.var.index].X.toarray(), columns=a.var.index, index=adata.obs.index)\n",
    "        obs_donor_data = pd.merge(obs_data,adata.obs['donor_id'], how='left',left_index=True, right_index=True)\n",
    "        df = obs_donor_data.groupby(['donor_id'])[obs_donor_data.columns].mean(numeric_only=True).reset_index() \n",
    "        v.append(df)\n",
    "    return region_dict\n",
    "\n",
    "def assign_sex(x,par_sum):\n",
    "    '''\n",
    "    Input: mean expression of gene\n",
    "    Output: assignment of sex\n",
    "    '''\n",
    "    if x >= 0.4 and par_sum > 0.001:\n",
    "        return 'male'\n",
    "    elif x < 0.4 and par_sum > 0.001:\n",
    "        return 'female'\n",
    "    elif par_sum < 0.001:\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        pass    \n",
    "    \n",
    "def calculate_sex(region_dict):\n",
    "    '''\n",
    "    Input: dictionary containing dataframes for PAR and Non-PAR average expression counts per gene per donor\n",
    "    Output: a dataframe of both nonpar and par summed expression counts per donor with sex assignment\n",
    "    '''\n",
    "    par_df = region_dict['par'][1]\n",
    "    par_df['par_sum'] = par_df.sum(numeric_only=True, axis=1)\n",
    "    nonpar_df = region_dict['nonpar'][1]\n",
    "    nonpar_df['nonpar_sum'] = nonpar_df.sum(numeric_only=True, axis=1)\n",
    "    nonpar_par_df = pd.merge(nonpar_df, par_df, how='left', left_index=True, right_index=True) \n",
    "    nonpar_par_df['nonPAR_to_PAR'] = nonpar_par_df['nonpar_sum']/nonpar_par_df['par_sum']\n",
    "    nonpar_par_df.rename(columns={'donor_id_x':'donor_id'}, inplace=True)\n",
    "    nonpar_par_df['scRNAseq_sex'] = nonpar_par_df.apply(lambda x: assign_sex(x['nonPAR_to_PAR'], x['par_sum']), axis=1)\n",
    "    return nonpar_par_df\n",
    "    \n",
    "def check_percent(par_adata,nonpar_adata,par_ids,nonpar_ids):\n",
    "    '''\n",
    "    Input: subset adatas and id lists\n",
    "    Output: percent of genes found per region\n",
    "    '''\n",
    "    print(f\"% PAR genes found: {(par_adata.shape[1]/len(par_ids))*100}\")\n",
    "    print(f\"% Non-PAR genes found: {(nonpar_adata.shape[1]/len(nonpar_ids))*100}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run scRNA-seq sex analysis**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get PAR & Non-PAR gene_ids from ref_file\n",
    "chry_file = 'ref_files/chry_regions.json'\n",
    "chry_genes = json.load(open(chry_file))\n",
    "par_ids = chry_genes['PAR']\n",
    "nonpar_ids = chry_genes['NONPAR']\n",
    "sex_field = 'sex'\n",
    "\n",
    "#Check metadata fields to include in final output\n",
    "fields_to_check = ['colllection_id','dataset_id','donor_id', sex_field,'development_stage','development_stage_ontology_term_id','self_reported_ethnicity','self_reported_ethnicity_ontology_term_id']\n",
    "metadata_list = [f for f in fields_to_check if f in adata.obs_keys()]\n",
    "\n",
    "if adata.raw:\n",
    "    par_adata = adata.raw[:,adata.raw.var.index.isin(par_ids)]\n",
    "    nonpar_adata = adata.raw[:,adata.raw.var.index.isin(nonpar_ids)] \n",
    "\n",
    "else: \n",
    "    par_adata = adata[:,adata.var.index.isin(par_ids)]\n",
    "    nonpar_adata = adata[:,adata.var.index.isin(nonpar_ids)] \n",
    "\n",
    "#Check how many par/nonpar genes were found in dataset\n",
    "check_percent(par_adata,nonpar_adata,par_ids,nonpar_ids)\n",
    "\n",
    "#Calculate scRNA-seq based sex\n",
    "region_counts = generate_regions_dict(par_adata,nonpar_adata,adata)\n",
    "donor_df = calculate_sex(region_counts)\n",
    "donor_df = donor_df[['donor_id','nonpar_sum','par_sum','nonPAR_to_PAR','scRNAseq_sex']].merge(adata.obs[metadata_list].drop_duplicates(), on='donor_id', how='left')\n",
    "donor_df = pd.merge(donor_df, adata.obs.groupby('donor_id').size().reset_index(name='cell_counts'), how='left', left_on='donor_id', right_on='donor_id')\n",
    "donor_df[donor_df['scRNAseq_sex'] != donor_df[sex_field]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# var\n",
    "**Check for Ensembl IDs, redundant fields, etc.**<br>\n",
    "**Check for schema fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similar checks for raw.var, if present**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.raw.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw counts\n",
    "*Check if any observations have exactly the same raw count vector to identify possible duplication*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if adata.raw:\n",
    "    hashes = [hash(r.tobytes()) for r in adata.raw.X.toarray()]\n",
    "else:\n",
    "    hashes = [hash(r.tobytes()) for r in adata.X.toarray()]\n",
    "\n",
    "hash_df = adata.obs.copy()\n",
    "hash_df['hashes'] = hashes\n",
    "hash_df = hash_df[hash_df.duplicated(subset='hashes',keep=False) == True]\n",
    "hash_df.sort_values('hashes', inplace=True)\n",
    "hash_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate\n",
    "**Determine the embedding by which to plot**\\\n",
    "May need to overwrite if the first obsm is not informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_embedding = adata.uns.get('default_embedding')\n",
    "umap_embedding = None\n",
    "tsne_embdding = None\n",
    "for k in adata.obsm_keys():\n",
    "    if 'umap' in k.lower():\n",
    "        umap_embedding = k\n",
    "    elif 'tsne' in k.lower():\n",
    "        tsne_embdding = k\n",
    "if not default_embedding:\n",
    "    if umap_embedding:\n",
    "        default_embedding = umap_embedding\n",
    "    elif tsne_embdding:\n",
    "        default_embedding = tsne_embdding\n",
    "    else:\n",
    "        default_embedding = adata.obsm_keys()[0]\n",
    "default_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the cells to ensure they cluster by cell type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cell_type_ontology_term_id_colors' in adata.uns:\n",
    "    remove_ctoti_colors = False\n",
    "else:\n",
    "    remove_ctoti_colors = True\n",
    "\n",
    "sc.set_figure_params(dpi=150)\n",
    "sc.pl.embedding(adata, basis=default_embedding, color=['cell_type_ontology_term_id'])\n",
    "#The above plot will set a color palette in uns, so remove that\n",
    "if remove_ctoti_colors:\n",
    "    del adata.uns['cell_type_ontology_term_id_colors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot by multiple genes using the normalized counts**<br>\n",
    "*It is best to get a list of genes relevant to the specific data from the contributor/publication*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_list = [\n",
    "    'CD34',\n",
    "    'IGLL1',\n",
    "    'TRGC2',\n",
    "    'CCR9',\n",
    "    'CCR7',\n",
    "    'HIVEP3',\n",
    "    'TOX2',\n",
    "    'RAG1',\n",
    "    'RAG2',\n",
    "    'PCNA',\n",
    "    'CDK1'\n",
    "]\n",
    "\n",
    "ref_files = [\n",
    "    'genes_ercc.csv',\n",
    "    'genes_homo_sapiens.csv',\n",
    "    'genes_mus_musculus.csv',\n",
    "    'genes_sars_cov_2.csv'\n",
    "]\n",
    "\n",
    "ref_dir = 'ref_files/'\n",
    "if not os.path.exists(ref_dir + 'genes_approved.csv'):\n",
    "    ids = pd.DataFrame()\n",
    "    for f in ref_files:\n",
    "        df = pd.read_csv(f, names=['feature_id','symb','num','length'],dtype='str',index_col=False)\n",
    "        ids = ids.append(df)\n",
    "        os.remove(f)\n",
    "    ids.to_csv(ref_dir + 'genes_approved.csv', index=False)\n",
    "\n",
    "approved = pd.read_csv(ref_dir + 'genes_approved.csv',dtype='str')\n",
    "\n",
    "ensg_list = []\n",
    "for s in symbol_list:\n",
    "    if s in approved['symb'].tolist():\n",
    "        ensg_id = approved.loc[approved['symb'] == s, 'feature_id'].iloc[0]\n",
    "        if ensg_id in adata.var.index:\n",
    "            ensg_list.append(ensg_id)\n",
    "            print(ensg_id + ' -- ' + s)\n",
    "        else:\n",
    "            s = s[0] + s[1:].lower()\n",
    "            if s in approved['symb'].tolist():\n",
    "                ensg_id = approved.loc[approved['symb'] == s, 'feature_id'].iloc[0]\n",
    "                if ensg_id in adata.var.index:\n",
    "                    ensg_list.append(ensg_id)\n",
    "                    print(ensg_id + ' -- ' + s)\n",
    "                else:\n",
    "                    print(f'{s}/{ensg_id} not found in var')    \n",
    "            else:\n",
    "                print(f'{s} not found in gene file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(adata, basis=default_embedding, color=ensg_list, use_raw=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare with the same genes using the raw counts to confirm they are correlated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(adata, basis=default_embedding, color=ensg_list, use_raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additionally, you could compare dotplots of those genes in each cell population**\\\n",
    "*This will scale all genes based on the max range of any gene so 1 gene with high values may make others difficult to distinguish*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.dotplot(adata, ensg_list, 'cell_type_ontology_term_id', use_raw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.dotplot(adata, ensg_list, 'cell_type_ontology_term_id', use_raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If it is spatial data, test if the image and X_spatial embeddings enable scanpy use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(adata, color='cell_type_ontology_term_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If updates have been made, write the revised file**\\\n",
    "*`compression='gzip'` is critical here to keep the file size down*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_one = file.replace('.h5ad','_revised.h5ad')\n",
    "adata.write(filename=new_one, compression='gzip')\n",
    "new_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the CELLxGENE validator on the revised file**<br>\n",
    "*This is the same as running `cellxgene-schema validate <file>` in the terminal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_process = subprocess.run(['cellxgene-schema', 'validate', new_one], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "for line in validate_process.stdout.decode('utf-8').split('\\n'):\n",
    "    print(line)\n",
    "for line in validate_process.stderr.decode('utf-8').split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
