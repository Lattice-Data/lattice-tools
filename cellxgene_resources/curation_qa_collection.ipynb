{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import tarfile\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02337314",
   "metadata": {},
   "source": [
    "**Specify the locations of the cloned [single-cell-curation repo](https://github.com/chanzuckerberg/single-cell-curation) & your API key file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fdef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scc_repo_loc = os.path.expanduser('~/GitClones/CZI/')\n",
    "api_key_file_path = os.path.expanduser('~/Documents/keys/cxg-api-key-dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd3206",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(scc_repo_loc + 'single-cell-curation/notebooks/curation_api/python/'))\n",
    "\n",
    "\n",
    "from src.utils.config import set_api_access_config\n",
    "from src.collection import get_collection\n",
    "\n",
    "\n",
    "set_api_access_config() #use env='dev' to work on the dev site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b224b9-ee87-43ba-aa5a-6ef35ed4a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_urls = {\n",
    "    'data.humancellatlas.org/explore/projects/': 'hca',\n",
    "    'ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GS': 'geo',\n",
    "    'ncbi.nlm.nih.gov/projects/gap': 'dbgap',\n",
    "    'ncbi.nlm.nih.gov/bioproject/?term=PRJ': 'bioproj',\n",
    "    'ega-archive.org': 'ega',\n",
    "    'ebi.ac.uk/ena/browser/view/': 'ena',\n",
    "    'ebi.ac.uk/biostudies/arrayexpress/studies/E-MTAB': 'arrex',\n",
    "    'assets.nemoarchive.org/': 'nemo'\n",
    "}\n",
    "\n",
    "\n",
    "def parse_url(url):\n",
    "    for k,v in base_urls.items():\n",
    "        if k in url:\n",
    "            return v\n",
    "    return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f560c9c-89d6-4fa1-89fd-9535782e5cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_raw_data_formats = ['fastq','TenX','bam']\n",
    "\n",
    "\n",
    "def validate_raw_ncbi(acc):\n",
    "    prj_flag = False\n",
    "    if acc.startswith('GS'):\n",
    "        url1 = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=bioproject&term={acc}[Project Accession]&retmode=json'\n",
    "        r1 = requests.get(url1).json()\n",
    "        if r1['esearchresult']['idlist']:\n",
    "            i = r1['esearchresult']['idlist'][0] #list of ids, ideally - only search entry type:Series\n",
    "            url2 = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=bioproject&id={i}'\n",
    "            r2 = requests.get(url2)\n",
    "            responseXml = ET.fromstring(r2.text)\n",
    "            for a in responseXml.iter('ArchiveID'):\n",
    "                prj = a.attrib['accession']\n",
    "                prj_flag = True\n",
    "    else:\n",
    "        prj = acc\n",
    "        prj_flag = True\n",
    "\n",
    "    #some GSE don't return any results searching bioproject - e.g. GSM5027160\n",
    "    if not prj_flag:\n",
    "        url5 = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=gds&term={acc}[GEO Accession]&retmode=json'\n",
    "        r5 = requests.get(url5).json()\n",
    "        if r5['esearchresult']['idlist']:\n",
    "            i = r5['esearchresult']['idlist'][0] #list of ids, ideally - only search entry type:Series\n",
    "\n",
    "            url6 = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=gds&id={i}'\n",
    "            r6 = requests.get(url6)\n",
    "            for line in r6.text.split('\\n'):\n",
    "                if line.startswith('SRA Run Selector:'):\n",
    "                    prj_flag = True\n",
    "                    prj = line.split('acc=')[-1]\n",
    "\n",
    "    if prj_flag:\n",
    "        url3 = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=sra&term={prj}&retmode=json&retmax=100000'\n",
    "        r3 = requests.get(url3).json()\n",
    "        idlist = r3['esearchresult']['idlist']\n",
    "        sublists = [idlist[i:i+500] for i in range(0, len(idlist), 500)]\n",
    "        for sub in sublists:\n",
    "            ids = ','.join(sub)\n",
    "            url4 = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=sra&id={ids}'\n",
    "            r4 = requests.get(url4)\n",
    "            #parse the records for needed information & write report\n",
    "            responseXml = ET.fromstring(r4.text)\n",
    "            for ep in responseXml.iter('EXPERIMENT_PACKAGE'):\n",
    "                for run in ep.iter('RUN'):\n",
    "                    for cf in run.iter('CloudFile'):\n",
    "                        if cf.attrib['filetype'] in ncbi_raw_data_formats:\n",
    "                            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b9bb0-69f8-447a-badb-0fc3adaf82c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hca_raw_data_formats = ['fastq.gz','fastq','fq.gz']\n",
    "\n",
    "\n",
    "def validate_raw_hca(url):\n",
    "    api_base = 'https://service.azul.data.humancellatlas.org' \n",
    "    pj_id = url.split('/')[-1]\n",
    "    query = {\n",
    "        'projectId': {'is': [pj_id]}\n",
    "    }\n",
    "    q_url = f'{api_base}/index/files/?filters={json.dumps(query)}&size=250'\n",
    "    r = requests.get(q_url, headers={'Content-Type': 'application/json'}).json()\n",
    "    hits = r['hits']\n",
    "    while r['pagination']['next']:\n",
    "        next_endpoint = r['pagination']['next']\n",
    "        r = requests.get(next_endpoint).json()\n",
    "        hits.extend(r['hits'])\n",
    "    formats_in_prj = set([f['format'] for h in hits for f in h['files']])\n",
    "    present = [f for f in hca_raw_data_formats if f in formats_in_prj]\n",
    "    if present:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d21d2f-57ef-4c8f-8271-d7a5222a2f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_raw_arrex(url):\n",
    "    acc = url.split('/')[-1]\n",
    "    api_base = 'https://www.ebi.ac.uk/biostudies/api/v1'\n",
    "    q_url = f'{api_base}/studies/{acc}/info'\n",
    "    r = requests.get(q_url).json()\n",
    "    ftp_link = r['ftpLink']\n",
    "\n",
    "    ftp = ftplib.FTP('ftp.ebi.ac.uk', 'anonymous', 'anonymous@')\n",
    "    ftp.cwd(ftp_link.replace('ftp://ftp.ebi.ac.uk','') + '/Files')\n",
    "\n",
    "    filename = f'{acc}.sdrf.txt' #f'{acc}.sdrf.txt' is a tab-delimited with some fastq names\n",
    "    with open(filename, 'wb') as file:\n",
    "        ftp.retrbinary(f'RETR {filename}', file.write)\n",
    "\n",
    "    erxs = []\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "    for c in df.columns:\n",
    "        if '[ENA_EXPERIMENT]' in c:\n",
    "            erxs.extend(df[c].dropna().unique())\n",
    "    os.remove(filename)\n",
    "\n",
    "    ftp.quit()\n",
    "\n",
    "    if erxs:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f654a-20a5-4f0f-9392-3d8cb2c5593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nemo_raw_data_formats = ['fastq.tar']\n",
    "\n",
    "\n",
    "def validate_raw_nemo(url):\n",
    "    for df in pd.read_html(url):\n",
    "        if 'Dataset Collection URL' in df['Field'].unique():\n",
    "            coll_url = df.loc[df['Field'] == 'Dataset Collection URL']['Value'].iloc[0]\n",
    "            if str(coll_url).endswith('.tgz'):\n",
    "                r = requests.get(coll_url)\n",
    "                with open('temp.tgz','wb') as f:\n",
    "                    f.write(r.content)\n",
    "                file_list = []\n",
    "                tar = tarfile.open('temp.tgz', 'r:gz')\n",
    "                for item in tar:\n",
    "                    if item.name.endswith('fetch.txt'):\n",
    "                        tar.extract(item)\n",
    "                        with open(item.name, 'r') as f:\n",
    "                            for line in (f.read().split('\\n')):\n",
    "                                file_list.append(line.split('\\t')[0])\n",
    "                        os.remove(item.name)\n",
    "                        os.rmdir(item.name.split('/')[0])\n",
    "                        os.remove('temp.tgz')\n",
    "                raw_files = [f for f in file_list if f.endswith(tuple(nemo_raw_data_formats))]\n",
    "                if raw_files:\n",
    "                    return True\n",
    "        else:\n",
    "            i = df.loc[df['Field'] == 'Identifier']['Value'].iloc[0].split(':')[1]\n",
    "            raw_present = validate_raw_nemo('https://assets.nemoarchive.org/' + i)\n",
    "            if raw_present == True:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0531631-8546-4565-a47d-f074621dee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://metadata.ega-archive.org/spec\n",
    "ega_raw_data_formats = ['fastq.gz','bam','cram']\n",
    "\n",
    "\n",
    "def validate_raw_ega(url):\n",
    "    acc = url.split('/')[-1]\n",
    "    obj_type = url.split('/')[-2]\n",
    "    api_base = 'https://metadata.ega-archive.org'\n",
    "\n",
    "    if obj_type == 'studies':\n",
    "        ds_query = f'{api_base}/studies/{acc}/datasets?limit=100000'\n",
    "        response = requests.get(ds_query).json()\n",
    "        datasets = [d['accession_id'] for d in response]\n",
    "    else:\n",
    "        datasets = [acc]\n",
    "\n",
    "    for d in datasets:\n",
    "        files_query = f'{api_base}/datasets/{d}/files?limit=100000'\n",
    "        response = requests.get(files_query).json()\n",
    "        raw_files = [r for r in response if r['extension'] in ega_raw_data_formats]\n",
    "        if raw_files:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf01cc5",
   "metadata": {},
   "source": [
    "**Specify the Collection to upload to**<br>\n",
    "If a Revision, use the Revision ID, not the Published ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check is_primary_data\n",
    "collection = get_collection(collection_id)\n",
    "pd.DataFrame(collection['datasets'])[['title','dataset_id','is_primary_data','cell_count','primary_cell_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32618d83-5f17-4cad-8656-4c39b00bd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check raw data links\n",
    "#check GEO link is named after accession\n",
    "#array express too?\n",
    "#dbgap shouldn't include the version\n",
    "for l in collection['links']:\n",
    "    raw_present = False\n",
    "    url,ltype = l['link_url'],l['link_type']\n",
    "    name = 'NO NAME' if not l['link_name'] else l['link_name']\n",
    "    resource = parse_url(url)\n",
    "\n",
    "    if resource in ['geo','bioproj','ena','dbgap']:\n",
    "        acc = url.split('=')[-1].split('/')[-1]\n",
    "        raw_present = validate_raw_ncbi(acc)\n",
    "        if acc not in name:\n",
    "            print(f'ERROR: expecting {url} to be named {acc}, not {name}')\n",
    "    elif resource == 'hca':\n",
    "        raw_present = validate_raw_hca(url)\n",
    "    elif resource == 'arrex':\n",
    "        raw_present = validate_raw_arrex(url)\n",
    "    elif resource == 'nemo':\n",
    "        raw_present = validate_raw_nemo(url)\n",
    "    elif resource == 'ega':\n",
    "        raw_present = validate_raw_ega(url)\n",
    "\n",
    "    if raw_present and ltype != 'RAW_DATA':\n",
    "        print(f'ERROR: raw data found at {url}, expecting RAW DATA link_type, not {ltype}')\n",
    "    elif not raw_present and ltype == 'RAW_DATA':\n",
    "        print(f'ERROR: link_type:RAW DATA but raw data not found at {url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776819a-dcbd-478c-938b-c3b4868aae41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
