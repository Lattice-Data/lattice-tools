{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from IPython.display import display\n",
    "from cellxgene_mods import CxG_API,compare_revision,report\n",
    "\n",
    "sys.path.append('..')\n",
    "from public_resources.public_resources import detect_sequence_data\n",
    "\n",
    "\n",
    "CxG_API.config() # set env='dev' or 'staging' if working in either of those test environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf01cc5",
   "metadata": {},
   "source": [
    "**Specify the Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a8658-fecc-493a-9395-8e5545ea8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = ''\n",
    "my_dir = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e969a67b-dba3-450e-a217-07926cc26de6",
   "metadata": {},
   "source": [
    "**General QA**\n",
    "- If Revsion, review updates\n",
    "- Check for consortia\n",
    "- Check for duplicate Dataset titles\n",
    "- Review is_primary_data curation within Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = CxG_API.get_collection(collection_id)\n",
    "\n",
    "#CAN WE GET THINGS DOWNLOADING IN PARALLEL WHILE WE CHECK OTHER STUFF?\n",
    "#OR AT LEAST IN THE BACKGROUND?\n",
    "#download to my_dir\n",
    "for d in collection['datasets']:\n",
    "    if d['cell_count'] > 1:\n",
    "        for a in d['assets']:\n",
    "            if a['filetype'] == 'H5AD':\n",
    "                file = a['url'].split('/')[-1]\n",
    "                print(file)\n",
    "                if os.path.exists(file) == False:\n",
    "                    print('Downloading')\n",
    "                    with requests.get(a['url'], stream=True) as res:\n",
    "                        res.raise_for_status()\n",
    "                        with open(file, \"wb\") as df:\n",
    "                            for chunk in res.iter_content(chunk_size=1024 * 1024):\n",
    "                                df.write(chunk)\n",
    "\n",
    "if collection.get('revising_in') or collection.get('revision_of'):\n",
    "    collection = compare_revision(collection)\n",
    "    \n",
    "if not collection.get('consortia'):\n",
    "    report('No consortia - confirm this is correct', 'WARNING')\n",
    "\n",
    "df = pd.DataFrame(collection['datasets'])[['title','dataset_id','is_primary_data','cell_count','primary_cell_count']]\n",
    "if not df[df.duplicated(subset='title', keep=False)].empty:\n",
    "    report('non-unique Dataset titles','ERROR')\n",
    "    display(df[df.duplicated(subset='title', keep=False)].sort_values('title'))\n",
    "\n",
    "df.sort_values('is_primary_data', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900b4f7-7fcc-4a66-b6a2-0861755ae900",
   "metadata": {},
   "source": [
    "**Validate links for presence of raw sequence data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32618d83-5f17-4cad-8656-4c39b00bd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_link = False\n",
    "for l in collection['links']:\n",
    "    raw_formats_present = detect_sequence_data(l['link_url'])\n",
    "\n",
    "    if raw_present != 'undetermined':\n",
    "        if raw_formats_present:\n",
    "            raw_data_link = True\n",
    "            if l['link_type'] != 'RAW_DATA':\n",
    "                report(f'raw data found at {url}, expecting link_type:RAW DATA, not {l[\"link_type\"]}', 'ERROR')\n",
    "        elif not raw_formats_present and l['link_type'] == 'RAW_DATA':\n",
    "            report(f'link_type:RAW DATA but raw data not found at {l[\"link_url\"]}', 'ERROR')\n",
    "\n",
    "if not raw_data_link:\n",
    "    report('No raw data link present', 'WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd0ecbd-69fd-4178-b2a7-d09c85cf15d1",
   "metadata": {},
   "source": [
    "**QA Donor metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee3acce-4424-448b-8208-dc9963f4e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obs = pd.DataFrame()\n",
    "for f in os.listdir(my_dir):\n",
    "    if f.endswith('.h5ad'):\n",
    "        adata = sc.read_h5ad(my_dir + f, backed='r')\n",
    "        adata.obs['title'] = adata.uns['title']\n",
    "        all_obs = pd.concat([all_obs, adata.obs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6859e-1c5e-4037-8d69-3266b41e7f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_fields = ['donor_id',\n",
    "                'sex',\n",
    "                'sex_ontology_term_id',\n",
    "                'development_stage_ontology_term_id',\n",
    "                'development_stage',\n",
    "                'self_reported_ethnicity_ontology_term_id',\n",
    "                'self_reported_ethnicity',\n",
    "                'disease_ontology_term_id',\n",
    "                'disease',\n",
    "                'tissue_type',\n",
    "                'data_source'\n",
    "               ]\n",
    "\n",
    "donor_df = pd.DataFrame(all_obs[donor_fields].value_counts()).reset_index()\n",
    "inconsistencies = donor_df[donor_df.duplicated(subset='donor_id', keep=False) == True].sort_values('donor_id')\n",
    "if not inconsistencies.empty:\n",
    "    report('donor metadata inconsistencies', 'ERROR')\n",
    "    display(inconsistencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a90df5-7373-4530-8738-43e479a0631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells = 'Oral and Craniofacial Atlas'\n",
    "all_cells_donors = all_obs[all_obs['title'] == all_cells]['donor_id'].unique()\n",
    "new_donors = [d for d in all_obs['donor_id'].unique() if d not in all_cells_donors]\n",
    "new_donors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18b9bf-70a0-4e45-a572-c88f4b02eea6",
   "metadata": {},
   "source": [
    "**look for consistency with other isntances of the donors across CELLxGENE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02383a6-70f6-4193-b158-5d8be412bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = CxG_API.get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cbc24b-7226-4fc2-b1e1-f0dadf1c23d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    donor_match = [d for d in donor_df['donor_id'].unique() if d in dataset['donor_id']]\n",
    "    if donor_match:\n",
    "        print(dataset['collection_id'], donor_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d6cc31-7155-4445-9fa0-ac17ea524568",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_donor_datasets = []\n",
    "for d in cxg_datasets:\n",
    "    if True in d['is_primary_data']:\n",
    "        donor_match = [p for p in donor_df['donor_id'].unique() if p in d['donor_id']]\n",
    "        if donor_match:\n",
    "            shared_donor_datasets.append(d)\n",
    "\n",
    "reused_obs = pd.DataFrame()\n",
    "for d in shared_donor_datasets:\n",
    "    with h5py.File(\n",
    "        fs.open(f\"corpora-data-prod/{d['dataset_version_id']}/local.h5ad\")\n",
    "    ) as f:\n",
    "        obs = read_elem(f[\"obs\"])\n",
    "        obs['title'] = d['title']\n",
    "        reused_obs = pd.concat([reused_obs, obs])\n",
    "reused_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f1f30-363a-4cf3-87db-8600915f2b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_obs = pd.concat([all_obs, reused_obs])\n",
    "donor_fields = ['donor_id',\n",
    "                'sex',\n",
    "                'development_stage',\n",
    "                'self_reported_ethnicity',\n",
    "                'disease']\n",
    "\n",
    "donor_df = concat_obs[donor_fields]\n",
    "donor_df['development_stage'] = donor_df['development_stage'].apply(lambda x: x.replace('human stage','stage'))\n",
    "donor_df = pd.DataFrame(donor_df.value_counts()).reset_index()\n",
    "inconsistencies = donor_df[donor_df.duplicated(subset='donor_id', keep=False) == True].sort_values('donor_id')\n",
    "if not inconsistencies.empty:\n",
    "    report('donor metadata inconsistencies', 'ERROR')\n",
    "    display(inconsistencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74db854d-5262-43a6-94d5-43deb4227801",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_obs[concat_obs['donor_id'].isin(['284C'])][['donor_id','title','development_stage']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39effb73-1cba-44a3-8230-28f114753a53",
   "metadata": {},
   "source": [
    "**QA many spatial Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d076db-843a-45eb-86b0-efa4cf562271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visim + 4992 - is_primary_data:True - else False\n",
    "#^is_single\n",
    "\n",
    "symbols = [\n",
    "    'CD34',\n",
    "    'IGLL1',\n",
    "    'TRGC2',\n",
    "    'CCR9',\n",
    "    'CCR7',\n",
    "    'HIVEP3',\n",
    "    'TOX2',\n",
    "    'RAG1',\n",
    "    'RAG2',\n",
    "    'PCNA',\n",
    "    'CDK1'\n",
    "]\n",
    "\n",
    "for d in collection['datasets']:\n",
    "    if 'Visium' in d['assay'][0]['label'] and d['cell_count'] == 4992:\n",
    "        for a in d['assets']:\n",
    "            if a['filetype'] == 'H5AD':\n",
    "                file = '/Users/jason/Downloads/' + a['url'].split('/')[-1]\n",
    "                if os.path.exists(file) == False:\n",
    "                    with requests.get(a['url'], stream=True) as res:\n",
    "                        res.raise_for_status()\n",
    "                        with open(file, \"wb\") as df:\n",
    "                            for chunk in res.iter_content(chunk_size=1024 * 1024):\n",
    "                                df.write(chunk)\n",
    "        adata = sc.read_h5ad(file)\n",
    "        print(file)\n",
    "        print(adata.uns['title'])\n",
    "    \n",
    "        evaluate_sparsity(adata)\n",
    "        evaluate_data(adata)\n",
    "    \n",
    "        if len(adata.var) < 15000:\n",
    "            report('Less than 15k genes present','ERROR')\n",
    "        elif len(adata.var) < 20000:\n",
    "            report('Less than 20k genes present','WARNING')\n",
    "\n",
    "        evaluate_dup_counts(adata)\n",
    "        ensg_list = symbols_to_ids(symbols, adata.var)\n",
    "        sc.pl.dotplot(adata, ensg_list, 'cell_type', use_raw=False)\n",
    "        if adata.raw:\n",
    "            sc.pl.dotplot(adata, ensg_list, 'cell_type', use_raw=True)\n",
    "        plot_vis(adata, 'cell_type')\n",
    "        print('-----------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
