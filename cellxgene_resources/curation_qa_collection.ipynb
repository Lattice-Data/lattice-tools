{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tarfile\n",
    "import xml.etree.ElementTree as ET\n",
    "from cellxgene_mods import CxG_API\n",
    "\n",
    "\n",
    "CxG_API.config() # set env='dev' or 'staging' if working in either of those test environments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a8658-fecc-493a-9395-8e5545ea8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb3d6c2-8221-48b1-a18b-1c6ec410671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "revision_flag = False\n",
    "collection = CxG_API.get_collection(collection_id)\n",
    "if collection.get('revising_in'):\n",
    "    revision_flag = True\n",
    "    revision_id = collection['revising_in']\n",
    "    revision = CxG_API.get_collection(revision_id)\n",
    "elif collection.get('revision_of'):\n",
    "    revision_flag = True\n",
    "    revision_id = collection_id\n",
    "    revision = collection\n",
    "    collection_id = collection['revision_of']\n",
    "    collection = collection = CxG_API.get_collection(collection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5992eb-d752-4d02-a943-483ef93f453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "should_differ_collection = [\n",
    "    'collection_id', 'collection_url', 'collection_version_id',\n",
    "    'created_at', 'revising_in', 'revision_of', 'visibility'\n",
    "]\n",
    "should_be_absent = [\n",
    "    'processing_status'\n",
    "]\n",
    "\n",
    "should_differ_dataset = [\n",
    "    'dataset_version_id','explorer_url','assets','revised_at','citation','processing_status'\n",
    "]\n",
    "\n",
    "ont_fields = [\n",
    "    'assay','cell_type','development_stage','disease',\n",
    "    'self_reported_ethnicity','sex','tissue','organism'\n",
    "]\n",
    "\n",
    "def compare_revision(collection, revision):\n",
    "    for k,v in revision.items():\n",
    "        if k not in collection.keys():\n",
    "            if k not in should_be_absent:\n",
    "                print('not present: ' + k)\n",
    "        elif collection.get(k) != v and k not in should_differ_collection:\n",
    "            if k == 'datasets':\n",
    "                diff_props = set()\n",
    "                pub_datasets = {d['dataset_id']: d for d in collection[k]}\n",
    "                rev_datasets = {d['dataset_id']: d for d in revision[k]}\n",
    "                comp = {}\n",
    "                new = {}\n",
    "                for ds_id,v in rev_datasets.items():\n",
    "                    if ds_id not in pub_datasets.keys():\n",
    "                        new[ds_id] = {'title': v['title']}\n",
    "                    else:\n",
    "                        comp[ds_id] = {'title': v['title']}\n",
    "                        for prop,rev_val in v.items():\n",
    "                            if prop not in should_differ_dataset:\n",
    "                                pub_val = pub_datasets[ds_id].get(prop)\n",
    "                                if prop in ont_fields:\n",
    "                                    rev_val = [t['label'] for t in rev_val]\n",
    "                                    pub_val = [t['label'] for t in pub_val]\n",
    "                                if isinstance(rev_val, list) and prop != 'assets':\n",
    "                                    rev_val.sort()\n",
    "                                    pub_val.sort()\n",
    "                                if pub_val != rev_val:\n",
    "                                    if prop == 'mean_genes_per_cell' and round(rev_val, 5) == round(pub_val, 5):\n",
    "                                        continue\n",
    "                                    diff_props.add(prop)\n",
    "                                    comp[ds_id][prop + '_REV'] = rev_val\n",
    "                                    comp[ds_id][prop + '_PUB'] = pub_val\n",
    "            else:\n",
    "                print('not same: ' + k)\n",
    "                if k not in ['datasets','publisher_metadata']:\n",
    "                    if k in ['links']:\n",
    "                        diff_in_pub = [l for l in collection[k] if l not in v]\n",
    "                        print('--- published: ', diff_in_pub)\n",
    "                        diff_in_rev = [l for l in v if l not in collection[k]]\n",
    "                        print('----- revised: ', diff_in_rev)\n",
    "                    else:\n",
    "                        print('--- published: ', str(collection[k]))\n",
    "                        print('----- revised: ', v)\n",
    "    \n",
    "    \n",
    "    comp_df = pd.DataFrame(comp).transpose()\n",
    "    comp_df = comp_df.dropna(subset=[c for c in comp_df.columns if c != 'title'], how='all')\n",
    "    if not comp_df.empty:\n",
    "        print('Revised Datasets')\n",
    "        a = ['title'] + [c[-3:] for c in comp_df.columns if c not in ['title']]\n",
    "        b = [''] + [c[:-4] for c in comp_df.columns if c not in ['title']]\n",
    "        comp_df.columns = [b, a]\n",
    "        display(comp_df.fillna(''))\n",
    "    \n",
    "        for f in diff_props:\n",
    "            temp = comp_df[(comp_df[f]['REV'] != comp_df[f]['PUB']) & (comp_df[f]['PUB'].isna() == False)]\n",
    "            for i,row in temp.iterrows():\n",
    "                p = row[f]['PUB']\n",
    "                if isinstance(p, (int, float)):\n",
    "                    continue\n",
    "                r = row[f]['REV']\n",
    "                only_in_pub = [str(e) for e in p if e not in r]\n",
    "                only_in_rev = [str(e) for e in r if e not in p]\n",
    "                print(i + '-' + f)\n",
    "                if only_in_pub:\n",
    "                    print('only in pub:' + ','.join(only_in_pub))\n",
    "                if only_in_rev:\n",
    "                    print('only in rev:' + ','.join(only_in_rev))\n",
    "                print('---------')\n",
    "    \n",
    "    if new:\n",
    "        print('New Datasets')\n",
    "        display(pd.DataFrame(new).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b224b9-ee87-43ba-aa5a-6ef35ed4a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_urls = {\n",
    "    'data.humancellatlas.org/explore/projects/': 'hca',\n",
    "    'ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GS': 'geo',\n",
    "    'ncbi.nlm.nih.gov/projects/gap': 'dbgap',\n",
    "    'ncbi.nlm.nih.gov/bioproject/?term=PRJ': 'bioproj',\n",
    "    'ega-archive.org': 'ega',\n",
    "    'ebi.ac.uk/ena/browser/view/': 'ena',\n",
    "    'ebi.ac.uk/biostudies/arrayexpress/studies/E-MTAB': 'arrex',\n",
    "    'assets.nemoarchive.org/': 'nemo'\n",
    "}\n",
    "\n",
    "\n",
    "def parse_url(url):\n",
    "    for k,v in base_urls.items():\n",
    "        if k in url:\n",
    "            return v\n",
    "    return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f560c9c-89d6-4fa1-89fd-9535782e5cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_raw_data_formats = ['fastq','TenX','bam']\n",
    "\n",
    "\n",
    "def validate_raw_ncbi(acc):\n",
    "    prj_flag = False\n",
    "    if acc.startswith('GS'):\n",
    "        url1 = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=bioproject&term={acc}[Project Accession]&retmode=json'\n",
    "        r1 = requests.get(url1).json()\n",
    "        if r1['esearchresult']['idlist']:\n",
    "            i = r1['esearchresult']['idlist'][0] #list of ids, ideally - only search entry type:Series\n",
    "            url2 = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=bioproject&id={i}'\n",
    "            r2 = requests.get(url2)\n",
    "            responseXml = ET.fromstring(r2.text)\n",
    "            for a in responseXml.iter('ArchiveID'):\n",
    "                prj = a.attrib['accession']\n",
    "                prj_flag = True\n",
    "    else:\n",
    "        prj = acc\n",
    "        prj_flag = True\n",
    "\n",
    "    #some GSE don't return any results searching bioproject - e.g. GSM5027160\n",
    "    if not prj_flag:\n",
    "        url5 = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=gds&term={acc}[GEO Accession]&retmode=json'\n",
    "        r5 = requests.get(url5).json()\n",
    "        if r5['esearchresult']['idlist']:\n",
    "            i = r5['esearchresult']['idlist'][0] #list of ids, ideally - only search entry type:Series\n",
    "\n",
    "            url6 = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=gds&id={i}'\n",
    "            r6 = requests.get(url6)\n",
    "            for line in r6.text.split('\\n'):\n",
    "                if line.startswith('SRA Run Selector:'):\n",
    "                    prj_flag = True\n",
    "                    prj = line.split('acc=')[-1]\n",
    "\n",
    "    if prj_flag:\n",
    "        url3 = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=sra&term={prj}&retmode=json&retmax=100000'\n",
    "        r3 = requests.get(url3).json()\n",
    "        idlist = r3['esearchresult']['idlist']\n",
    "        sublists = [idlist[i:i+500] for i in range(0, len(idlist), 500)]\n",
    "        for sub in sublists:\n",
    "            ids = ','.join(sub)\n",
    "            url4 = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=sra&id={ids}'\n",
    "            r4 = requests.get(url4)\n",
    "            #parse the records for needed information & write report\n",
    "            responseXml = ET.fromstring(r4.text)\n",
    "            for ep in responseXml.iter('EXPERIMENT_PACKAGE'):\n",
    "                for run in ep.iter('RUN'):\n",
    "                    for cf in run.iter('CloudFile'):\n",
    "                        if cf.attrib['filetype'] in ncbi_raw_data_formats:\n",
    "                            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b9bb0-69f8-447a-badb-0fc3adaf82c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hca_raw_data_formats = ['fastq.gz','fastq','fq.gz']\n",
    "\n",
    "\n",
    "def validate_raw_hca(url):\n",
    "    api_base = 'https://service.azul.data.humancellatlas.org' \n",
    "    pj_id = url.split('/')[-1]\n",
    "    query = {\n",
    "        'projectId': {'is': [pj_id]}\n",
    "    }\n",
    "    q_url = f'{api_base}/index/files/?filters={json.dumps(query)}&size=250'\n",
    "    r = requests.get(q_url, headers={'Content-Type': 'application/json'}).json()\n",
    "    hits = r['hits']\n",
    "    while r['pagination']['next']:\n",
    "        next_endpoint = r['pagination']['next']\n",
    "        r = requests.get(next_endpoint).json()\n",
    "        hits.extend(r['hits'])\n",
    "    formats_in_prj = set([f['format'] for h in hits for f in h['files']])\n",
    "    present = [f for f in hca_raw_data_formats if f in formats_in_prj]\n",
    "    if present:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d21d2f-57ef-4c8f-8271-d7a5222a2f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_raw_arrex(url):\n",
    "    acc = url.split('/')[-1]\n",
    "    api_base = 'https://www.ebi.ac.uk/biostudies/api/v1'\n",
    "    q_url = f'{api_base}/studies/{acc}/info'\n",
    "    r = requests.get(q_url).json()\n",
    "    ftp_link = r['ftpLink']\n",
    "\n",
    "    ftp = ftplib.FTP('ftp.ebi.ac.uk', 'anonymous', 'anonymous@')\n",
    "    ftp.cwd(ftp_link.replace('ftp://ftp.ebi.ac.uk','') + '/Files')\n",
    "\n",
    "    filename = f'{acc}.sdrf.txt' #f'{acc}.sdrf.txt' is a tab-delimited with some fastq names\n",
    "    with open(filename, 'wb') as file:\n",
    "        ftp.retrbinary(f'RETR {filename}', file.write)\n",
    "\n",
    "    erxs = []\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "    for c in df.columns:\n",
    "        if '[ENA_EXPERIMENT]' in c:\n",
    "            erxs.extend(df[c].dropna().unique())\n",
    "    os.remove(filename)\n",
    "\n",
    "    ftp.quit()\n",
    "\n",
    "    if erxs:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f654a-20a5-4f0f-9392-3d8cb2c5593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nemo_raw_data_formats = ['fastq.tar']\n",
    "\n",
    "\n",
    "def validate_raw_nemo(url):\n",
    "    for df in pd.read_html(url):\n",
    "        if 'Dataset Collection URL' in df['Field'].unique():\n",
    "            coll_url = df.loc[df['Field'] == 'Dataset Collection URL']['Value'].iloc[0]\n",
    "            if str(coll_url).endswith('.tgz'):\n",
    "                r = requests.get(coll_url)\n",
    "                with open('temp.tgz','wb') as f:\n",
    "                    f.write(r.content)\n",
    "                file_list = []\n",
    "                tar = tarfile.open('temp.tgz', 'r:gz')\n",
    "                for item in tar:\n",
    "                    if item.name.endswith('fetch.txt'):\n",
    "                        tar.extract(item)\n",
    "                        with open(item.name, 'r') as f:\n",
    "                            for line in (f.read().split('\\n')):\n",
    "                                file_list.append(line.split('\\t')[0])\n",
    "                        os.remove(item.name)\n",
    "                        os.rmdir(item.name.split('/')[0])\n",
    "                        os.remove('temp.tgz')\n",
    "                raw_files = [f for f in file_list if f.endswith(tuple(nemo_raw_data_formats))]\n",
    "                if raw_files:\n",
    "                    return True\n",
    "        else:\n",
    "            i = df.loc[df['Field'] == 'Identifier']['Value'].iloc[0].split(':')[1]\n",
    "            raw_present = validate_raw_nemo('https://assets.nemoarchive.org/' + i)\n",
    "            if raw_present == True:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0531631-8546-4565-a47d-f074621dee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://metadata.ega-archive.org/spec\n",
    "ega_raw_data_formats = ['fastq.gz','bam','cram']\n",
    "\n",
    "\n",
    "def validate_raw_ega(url):\n",
    "    acc = url.split('/')[-1]\n",
    "    obj_type = url.split('/')[-2]\n",
    "    api_base = 'https://metadata.ega-archive.org'\n",
    "\n",
    "    if obj_type == 'studies':\n",
    "        ds_query = f'{api_base}/studies/{acc}/datasets?limit=100000'\n",
    "        response = requests.get(ds_query).json()\n",
    "        datasets = [d['accession_id'] for d in response]\n",
    "    else:\n",
    "        datasets = [acc]\n",
    "\n",
    "    for d in datasets:\n",
    "        files_query = f'{api_base}/datasets/{d}/files?limit=100000'\n",
    "        response = requests.get(files_query).json()\n",
    "        raw_files = [r for r in response if r['extension'] in ega_raw_data_formats]\n",
    "        if raw_files:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf01cc5",
   "metadata": {},
   "source": [
    "**Specify the Collection**<br>\n",
    "If a Revision, use the Revision ID, not the Published ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if revision_flag:\n",
    "    compare_revision(collection, revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check is_primary_data\n",
    "collection = CxG_API.get_collection(collection_id)\n",
    "df = pd.DataFrame(collection['datasets'])[['title','dataset_id','is_primary_data','cell_count','primary_cell_count']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa887b1c-ed35-4e38-923b-fd15ddf116a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not collection.get('consortia'):\n",
    "    print('No consortia - confirm this is correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fbf178-ff76-4220-8486-31959462c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicated Dataset titles\n",
    "df[df.duplicated(subset='title', keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32618d83-5f17-4cad-8656-4c39b00bd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check raw data links\n",
    "#check GEO link is named after accession\n",
    "#array express too?\n",
    "#dbgap shouldn't include the version\n",
    "for l in collection['links']:\n",
    "    raw_present = False\n",
    "    url,ltype = l['link_url'],l['link_type']\n",
    "    name = 'NO NAME' if not l['link_name'] else l['link_name']\n",
    "    resource = parse_url(url)\n",
    "\n",
    "    if resource in ['geo','bioproj','ena','dbgap']:\n",
    "        acc = url.split('=')[-1].split('/')[-1]\n",
    "        raw_present = validate_raw_ncbi(acc)\n",
    "        if acc not in name:\n",
    "            print(f'ERROR: expecting {url} to be named {acc}, not {name}')\n",
    "    elif resource == 'hca':\n",
    "        raw_present = validate_raw_hca(url)\n",
    "    elif resource == 'arrex':\n",
    "        raw_present = validate_raw_arrex(url)\n",
    "    elif resource == 'nemo':\n",
    "        raw_present = validate_raw_nemo(url)\n",
    "    elif resource == 'ega':\n",
    "        raw_present = validate_raw_ega(url)\n",
    "\n",
    "    if raw_present and ltype != 'RAW_DATA':\n",
    "        print(f'ERROR: raw data found at {url}, expecting RAW DATA link_type, not {ltype}')\n",
    "    elif not raw_present and ltype == 'RAW_DATA':\n",
    "        print(f'ERROR: link_type:RAW DATA but raw data not found at {url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776819a-dcbd-478c-938b-c3b4868aae41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
