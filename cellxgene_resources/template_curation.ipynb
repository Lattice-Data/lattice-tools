{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import os\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import subprocess\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "portal_obs_fields = [\n",
    "    'assay',\n",
    "    'cell_type',\n",
    "    'development_stage',\n",
    "    'disease',\n",
    "    'ethnicity',\n",
    "    'organism',\n",
    "    'sex',\n",
    "    'tissue'\n",
    "]\n",
    "full_obs_standards = portal_obs_fields + [e + '_ontology_term_id' for e in portal_obs_fields] + ['is_primary_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the AnnData object\n",
    "**Update the name of the file (without the .h5ad extension)**<br>\n",
    "*The sample `my_matrix.h5ad` that is in this repo is subsampled from https://cellxgene.cziscience.com/e/f15e263b-6544-46cb-a46e-e33ab7ce8347.cxg/ with some metadata alterations for the purpose of this tutorial*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'my_matrix'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the AnnData object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(file + '.h5ad')\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data layers\n",
    "**If needed, transfer to sparse matrix format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_sparsity(x):\n",
    "    if isinstance(x, sparse.coo_matrix) or isinstance(x, sparse.csr_matrix) or isinstance(x, sparse.csc.csc_matrix):\n",
    "        sparsity = 1 - x.count_nonzero() / float(np.cumprod(x.shape)[-1])\n",
    "    elif isinstance(x, ndarray):\n",
    "        sparsity = 1 - count_nonzero(x) / float(np.cumprod(x.shape)[-1])\n",
    "    else:\n",
    "        print(f'matrix is of type {type(x)}, sparsity calculation has not been implemented')\n",
    "\n",
    "    return sparsity\n",
    "\n",
    "\n",
    "max_sparsity = 0.5\n",
    "\n",
    "sparsity = determine_sparsity(adata.X)\n",
    "print(f'X sparsity: {sparsity}')\n",
    "if sparsity > max_sparsity and type(adata.X) != sparse.csr.csr_matrix:\n",
    "    print('converting X to sparse')\n",
    "    adata.X = sparse.csr_matrix(adata.X)\n",
    "\n",
    "if adata.raw:\n",
    "    sparsity = determine_sparsity(adata.raw.X)\n",
    "    print(f'raw.X sparsity: {sparsity}')\n",
    "    if sparsity > max_sparsity and type(adata.raw.X) != sparse.csr.csr_matrix:\n",
    "        print('converting raw.X to sparse')\n",
    "        raw_adata = ad.AnnData(adata.raw.X, var=adata.raw.var, obs=adata.obs)\n",
    "        raw_adata.X = sparse.csr_matrix(raw_adata.X)\n",
    "        adata.raw = raw_adata\n",
    "        del raw_adata\n",
    "\n",
    "for l in adata.layers:\n",
    "    sparsity = determine_sparsity(adata.layers[l])\n",
    "    print(f'layers[{l}] sparsity: {sparsity}')\n",
    "    if sparsity > max_sparsity and type(adata.layers[l]) != sparse.csr.csr_matrix:\n",
    "        print(f'converting layers[{l}] to sparse')\n",
    "        adata.layers[l] = sparse.csr_matrix(adata.layers[l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the min/max of each layer**<br>\n",
    "*Look for duplicated or other unnecessary layers*<br>\n",
    "*Raw should be whole, positive, ~10<sup>3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if adata.raw:\n",
    "    print('raw min = ' + str(adata.raw.X.min()))\n",
    "    print('raw max = ' + str(adata.raw.X.max()))\n",
    "print('X min = ' + str(adata.X.min()))\n",
    "print('X max = ' + str(adata.X.max()))\n",
    "\n",
    "for l in adata.layers:\n",
    "    print(f'layers[{l}] min = ' + str(adata.layers[l].min()))\n",
    "    print(f'layers[{l}] max = ' + str(adata.layers[l].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** delete a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata.layers['other_raw']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obsm\n",
    "**Confirm at least one set of embeddings is present**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check that the default_embedding value, if defined, is in obsm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'default_embedding' in adata.uns:\n",
    "    de = adata.uns['default_embedding']\n",
    "    if de not in adata.obsm_keys():\n",
    "        print('ERROR:' + de + ' not in ' + ','.join(adata.obsm_keys()))\n",
    "    else:\n",
    "        print(de + ' is in ' + ','.join(adata.obsm_keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** update uns.default_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['default_embedding'] = 'X_umap'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# uns\n",
    "**Check for uns schema fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uns_schema =['schema_version','title','X_normalization']\n",
    "for p in uns_schema:\n",
    "    print(p + ': ' + adata.uns.get(p,'MISSING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** define uns.schema_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['schema_version'] = '2.0.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Browse all of uns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *_colors\n",
    "**scanpy & cellxgene allow for specification of cluster colors when coloring by specific obs fields**<br>\n",
    "**A list of color codes is specified in `uns.PROP_colors` where `PROP` is an obs field**<br>\n",
    "**The number of color codes in `uns.PROP_colors` must be at least as long as the number of unique values in `obs.PROP`**<br>\n",
    "<br>\n",
    "**Check for _colors fields & ensure each matches a categorical obs field**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numb_types = ['int_', 'int8', 'int16', 'int32', 'int64', 'uint8', 'uint16', 'uint32', 'uint64','float_', 'float16', 'float32', 'float64']\n",
    "\n",
    "for k in adata.uns.keys():\n",
    "    if k.endswith('_colors'):\n",
    "        colors = len(adata.uns[k])\n",
    "        obs_field = k[:-(len('_colors'))]\n",
    "\n",
    "        if obs_field.endswith('_ontology_term_id'):\n",
    "            label_field = obs_field[:-17]\n",
    "            print(f'WARNING: consider copying uns.{k} to uns.{label_field}_colors so palette transfers to CxG viz')\n",
    "\n",
    "        if obs_field in portal_obs_fields:\n",
    "            obs_field += '_ontology_term_id'\n",
    "        if obs_field not in adata.obs.keys():\n",
    "            print(f'WARNING: {obs_field} not found in obs, consider DELETING or RENAMING uns.{k}')\n",
    "        else:\n",
    "            values = len(adata.obs[obs_field].unique())\n",
    "            if colors < values:\n",
    "                print(f'ERROR: uns.{k} has only {str(colors)} colors but obs.{obs_field} has {str(values)} values')\n",
    "            if adata.obs.dtypes[obs_field].name in numb_types:\n",
    "                print(f'ERROR: uns.{k} is associated with non-categorical {obs_field}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensure the portal fields are not used**<br>\n",
    "**Ensure schema fields are present and values are valid & precise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in full_obs_standards:\n",
    "    print(o)\n",
    "    if o not in adata.obs_keys():\n",
    "        print('NOT IN OBS')\n",
    "    else:\n",
    "        un = adata.obs[o].unique()\n",
    "        if un.dtype == 'category':\n",
    "            print(un.to_list())\n",
    "        else:\n",
    "            print(un.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10x barcode checker\n",
    "**Checks a random 1k barcodes against 10x barcode lists**<br>\n",
    "*Can help confirm 3' v2 vs v3 vs multiome*<br>\n",
    "*5' v1 and v2 kits use the same barcode list as 3' v2*<br>\n",
    "*Requires the 3 barcode list files, stored in s3://submissions-lattice/cellranger-whitelist/*<br>\n",
    "*Assumes the barcode is in the index. Suffixes/prefixes are OK*<br>\n",
    "<br>\n",
    "**Define the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from random import randint\n",
    "\n",
    "\n",
    "def TENx_barcode_checker(df):\n",
    "    num_to_check = 1000\n",
    "\n",
    "    v2_file = '737K-august-2016.txt'\n",
    "    v3_file = '3M-february-2018.txt'\n",
    "    multiome_file = '737K-arc-v1.txt'\n",
    "\n",
    "    v2_list = [line.strip() for line in open(v2_file, 'r')]\n",
    "    v3_list = [line.strip() for line in open(v3_file, 'r')]\n",
    "    multiome_list = [line.strip() for line in open(multiome_file, 'r')]\n",
    "\n",
    "    cellcount = df.index.shape[0]\n",
    "    barcode_pattern = '[ACTG]{16}'\n",
    "    barcode_results = ''\n",
    "    if re.search(barcode_pattern, df.index[5,]):\n",
    "        cellcount\n",
    "        random_indices = [randint(0, cellcount - 1) for p in range(0, num_to_check)]\n",
    "        barcodes = {'3pv2_5pv1_5pv2': 0,'3pv3': 0,'multiome': 0,'multiple': 0,'none': 0}\n",
    "        for i in random_indices:\n",
    "            if re.search(barcode_pattern, df.index[i,]):\n",
    "                barcode = re.search(barcode_pattern, df.index[i,]).group(0)\n",
    "                if barcode in v2_list:\n",
    "                    if barcode in multiome_list:\n",
    "                        barcodes['multiple'] += 1\n",
    "                    elif barcode in v3_list:\n",
    "                        barcodes['multiple'] += 1\n",
    "                    else:\n",
    "                        barcodes['3pv2_5pv1_5pv2'] += 1\n",
    "                elif barcode in multiome_list:\n",
    "                    if barcode in v3_list:\n",
    "                        barcodes['multiple'] += 1\n",
    "                    else:\n",
    "                        barcodes['multiome'] += 1\n",
    "                elif barcode in v3_list:\n",
    "                    barcodes['3pv3'] += 1\n",
    "                else:\n",
    "                    barcodes['none'] += 1\n",
    "        return barcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check 1k barcodes across the whole obs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = TENx_barcode_checker(adata.obs)\n",
    "if not results:\n",
    "    print('no barcodes checked')\n",
    "pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additionally, can check 1k barcodes from multiple subsets of obs**<br>\n",
    "*Define `prop` and 1k barcodes will be checked for each unique value in `obs.prop`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = 'assay_ontology_term_id'\n",
    "\n",
    "results = []\n",
    "for a in adata.obs[prop].value_counts().keys():\n",
    "    print(a)\n",
    "    r = TENx_barcode_checker(adata.obs[adata.obs[prop] == a])\n",
    "    if r:\n",
    "        r[prop] = a\n",
    "        results.append(r)\n",
    "    else:\n",
    "        print('no barcodes checked')\n",
    "pd.DataFrame(results).set_index(prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** set a column with all the same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['is_primary_data'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** change column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_me = {\n",
    "    'cell_type': 'author_cell_type',\n",
    "    'ethnicity_ontology_id': 'ethnicity_ontology_term_id',\n",
    "    'disease_ontology_id': 'disease_ontology_term_id'\n",
    "}\n",
    "\n",
    "adata.obs.rename(columns=rename_me, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** fill null values of a specific column with a specified value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['sex_ontology_term_id'].cat.add_categories('unknown', inplace=True)\n",
    "adata.obs.fillna({'sex_ontology_term_id': 'unknown'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** adjust the values in a specific column in a standard way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_typo(x):\n",
    "    return x.replace('_',':')\n",
    "\n",
    "\n",
    "adata.obs['development_stage_ontology_term_id'] = adata.obs['development_stage_ontology_term_id'].apply(fix_typo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** replace specified values in specified columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_me = {\n",
    "    'organism_ontology_term_id':{'human':'NCBITaxon:9606', 'mouse': 'NCBITaxon:10090'},\n",
    "    'assay_ontology_term_id': {'EFO:0030003': 'EFO:0009899'}\n",
    "}\n",
    "\n",
    "adata.obs.replace(replace_me,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** add a new column with values based on values in an existing column<br>\n",
    "**Step 1:** get the values to map from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in adata.obs['author_cell_type'].unique():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** add a new column with values based on values in an existing column<br>\n",
    "**Step 2:** set up a dataframe with the mapping\n",
    "**Option A:** from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map in values based on another field - step 2: set up a dataframe with the mapping\n",
    "#option A: from dict\n",
    "celltypes = {\n",
    "    'Myeloid': 'CL:0001082',\n",
    "    'Endothelial': 'CL:0010008',\n",
    "    'Fibroblast': 'CL:0002548',\n",
    "    'Cardiomyocyte': 'CL:0000513',\n",
    "    'Pericyte': 'CL:0000669',\n",
    "    'Lymphoid': 'CL:0000838',\n",
    "    'Cycling cells': 'CL:0000003',\n",
    "    'vSMCs': 'CL:0000514',\n",
    "    'Neuronal': 'CL:0000006'\n",
    "}\n",
    "\n",
    "ct_df = pd.DataFrame.from_dict(celltypes,orient='index',columns=['cell_type_ontology_term_id']).reset_index().rename(columns={'index':'author_cell_type'})\n",
    "ct_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** add a new column with values based on values in an existing column<br>\n",
    "**Step 2:** set up a dataframe with the mapping<br>\n",
    "**Option B:** from a Google Sheet<br>\n",
    "*Google Sheet permissions must be Anyone with Link is a Viewer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_id = '15oG8v5BS6HMPqCehYQcujMZUq9PgQNpo8osKhO7yA5o'\n",
    "tab_name = 'Sheet1'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={tab_name}'\n",
    "ct_df = pd.read_csv(url)\n",
    "ct_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** add a new column with values based on values in an existing column<br>\n",
    "**Step 3:** merge the dataframe into obs<br>\n",
    "*`how='left'` is critical to ensure obs order is retained*<br>\n",
    "*`set_index` is critical to ensure the index is retained*<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs = adata.obs.merge(ct_df, on='author_cell_type',how='left').set_index(adata.obs.index) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look for general obs field issues and collect obs information to check for redundant information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_fields = []\n",
    "gradient_fields = []\n",
    "uber_dict = {}\n",
    "for o in adata.obs.keys():\n",
    "    vc_dict = adata.obs[o].value_counts(dropna=False).to_dict()\n",
    "    counts = '_'.join([str(c) for c in vc_dict.values()])\n",
    "    count_len = len(vc_dict.keys())\n",
    "    values = [str(i) for i in vc_dict.keys()]\n",
    "\n",
    "    if o.startswith(' ') or o.endswith(' ') or '  ' in o:\n",
    "        print('leading/trailing whitespace:' + o)\n",
    "\n",
    "    if o not in full_obs_standards and ' '.join(o.split()).lower() in full_obs_standards:\n",
    "        print('schema conflict:' + o)\n",
    "\n",
    "    if count_len == 1:\n",
    "        lone_v = str(list(vc_dict.keys())[0])\n",
    "        if o not in full_obs_standards:\n",
    "            print('all same value:' + o + ',' + lone_v)\n",
    "\n",
    "    numb_types = ['int_', 'int8', 'int16', 'int32', 'int64', 'uint8', 'uint16', 'uint32', 'uint64','float_', 'float16', 'float32', 'float64']\n",
    "    if adata.obs.dtypes[o].name in numb_types:\n",
    "        gradient_fields.append(o)\n",
    "    #check for long categories as they will not be enabled for coloring\n",
    "    elif count_len > 200:\n",
    "        long_fields.append(o)\n",
    "\n",
    "    #report value_counts to later look for redundancy\n",
    "    metadata = {\n",
    "        'values': values,\n",
    "        'property': o\n",
    "    }\n",
    "    if counts in uber_dict:\n",
    "        uber_dict[counts].append(metadata)\n",
    "    else:\n",
    "        uber_dict[counts] = [metadata]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comb value_counts to report possible redundancy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in uber_dict.items():\n",
    "    if '_' in k and not k.startswith('1_1'):\n",
    "        props = [e['property'] for e in v]\n",
    "        if len(v) > 1 and not all(elem in full_obs_standards for elem in props):\n",
    "            print('cells breakdown: ' + k)\n",
    "            for e in v:\n",
    "                print(e['property'])\n",
    "                #print(e['values'])\n",
    "            print('----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate any fields that may be redundant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[['sample','patient','age','development_stage_ontology_term_id']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for fields that aren't appropriate as gradient (e.g. cluster number)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update a gradient field to categorical, if needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['cluster_id'] = adata.obs['cluster_id'].map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List any categorical fields with more than 200 categories as they may not be useful in the visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List any obs columns to remove and remove them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_remove = [\n",
    "    'tissue',\n",
    "    'organism',\n",
    "    'ethnicity',\n",
    "    'assay',\n",
    "    'disease',\n",
    "    'sex',\n",
    "    'cell_type'\n",
    "]\n",
    "\n",
    "obs_remove = [o for o in obs_remove if o in adata.obs.columns]\n",
    "adata.obs.drop(columns=obs_remove, inplace=True)\n",
    "if obs_remove:\n",
    "    print('removed: ' + ','.join(obs_remove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensure the portal fields are not used**<br>\n",
    "**Ensure schema fields are present and values are valid & precise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in full_obs_standards:\n",
    "    print(o)\n",
    "    if o not in adata.obs_keys():\n",
    "        print('NOT IN OBS')\n",
    "    else:\n",
    "        un = adata.obs[o].unique()\n",
    "        if un.dtype == 'category':\n",
    "            print(un.to_list())\n",
    "        else:\n",
    "            print(un.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# var\n",
    "**Check for Ensembl IDs, redundant fields, etc.**<br>\n",
    "**Check for schema fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similar checks for raw.var, if present**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.raw.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If CellRanger may have been used for alignment, check against the default CellRanger references for matches in order to inform symbol-to-ID mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_12 = 'refdata-cellranger-GRCh38-1_2_0_genes_gtf.tsv'\n",
    "CR_30 = 'refdata-cellranger-GRCh38-3_0_0_genes_gtf.tsv'\n",
    "CR_2020 = 'refdata-gex-GRCh38-2020-A_genes_gtf.tsv'\n",
    "CR_hg19 = 'refdata-cellranger-hg19-1_2_0_genes_gtf.tsv'\n",
    "for v in [CR_12,CR_30,CR_2020,CR_hg19]:\n",
    "    map_df = pd.read_csv(v, sep='\\t')\n",
    "    print(v)\n",
    "    print(adata.var.merge(map_df,left_index=True,right_on='gene_symbols',how='inner').shape[0])\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fill in the mapping file to use to map symbols to Ensembl IDs**<br>\n",
    "*Expecting a .tsv with columns `gene_symbols` & `gene_ids`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_mapping_file = CR_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View what features are not mapped in this**<br>\n",
    "*Check for typos or other alterations to the symbols that can be fixed*<br>\n",
    "*Common to see many ending in `.1` or `-1` resulting from duplicated symbols in the reference*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_map_df = pd.read_csv(var_mapping_file, sep='\\t')\n",
    "adata.var[adata.var.index.isin(var_map_df['gene_symbols']) != True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the list of approved IDs to filter on**<br>\n",
    "*For the initial run, download the 4 genes_ csv files from https://github.com/chanzuckerberg/single-cell-curation/tree/main/cellxgene_schema_cli/cellxgene_schema/ontology_files*<br>\n",
    "*After that, if the `genes_approved.csv` is available locally, then the 4 genes_ files won't be necessary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_files = [\n",
    "    'genes_ercc.csv',\n",
    "    'genes_homo_sapiens.csv',\n",
    "    'genes_mus_musculus.csv',\n",
    "    'genes_sars_cov_2.csv'\n",
    "]\n",
    "\n",
    "if not os.path.exists('genes_approved.csv'):\n",
    "    ids = pd.DataFrame()\n",
    "    for f in ref_files:\n",
    "        df = pd.read_csv(f, names=['feature_id','symb','num','length'],dtype='str',index_col=False)\n",
    "        ids = ids.append(df)\n",
    "        os.remove(f)\n",
    "    ids.to_csv('genes_approved.csv', index=False)\n",
    "\n",
    "approved = pd.read_csv('genes_approved.csv',dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** set columns with all the same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var['feature_biotype'] = 'gene'\n",
    "adata.var['feature_is_filtered'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove any fields (typically symbols as the portal will add those)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_remove = [\n",
    "    'gene_symbols'\n",
    "]\n",
    "\n",
    "adata.var.drop(columns=var_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Map the Ensembl IDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var = adata.var.merge(var_map_df,left_index=True,right_on='gene_symbols',how='left').set_index(adata.var.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter out genes that don't appear in the approved annotation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_to_keep = adata.var.index.tolist()\n",
    "var_in_approved = adata.var.index[adata.var['gene_ids'].isin(approved['feature_id'])].tolist()\n",
    "var_to_keep = [e for e in var_to_keep if e in var_in_approved]\n",
    "adata = adata[:, var_to_keep]\n",
    "adata.var.set_index('gene_ids',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeat much of the same steps for the `raw.var`, if it exists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_var_remove = [\n",
    "    'gene_symbols'\n",
    "]\n",
    "adata.raw.var.drop(columns=raw_var_remove, inplace=True)\n",
    "\n",
    "adata.raw.var['feature_biotype'] = 'gene'\n",
    "\n",
    "raw_adata = ad.AnnData(adata.raw.X, var=adata.raw.var, obs=adata.obs)\n",
    "\n",
    "raw_adata.var = raw_adata.var.merge(var_map_df,left_index=True,right_on='gene_symbols',how='left').set_index(raw_adata.var.index)\n",
    "\n",
    "raw_adata = raw_adata[:, var_to_keep]\n",
    "raw_adata.var.set_index('gene_ids',inplace=True)\n",
    "adata.raw = raw_adata\n",
    "adata.raw.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate\n",
    "**Determine the embedding by which to plot**\\\n",
    "May need to overwrite if the first obsm is not informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_embedding = adata.uns.get('default_embedding',adata.obsm_keys()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the cells to ensure they cluster by cell type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(dpi=150)\n",
    "sc.pl.embedding(adata, basis=default_embedding, color=['cell_type_ontology_term_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above plot will set a color palette in uns, so remove that**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata.uns['cell_type_ontology_term_id_colors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot by multiple genes using the normalized counts**<br>\n",
    "*It is best to get a list of genes relevant to the specific data from the contributor/publication*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_list = [\n",
    "    'CD19',\n",
    "    'NCAM1',\n",
    "    'CD3G',\n",
    "    'MUC2',\n",
    "    'COL1A1'\n",
    "]\n",
    "\n",
    "ensg_list = []\n",
    "for s in symbol_list:\n",
    "    if s in approved['symb'].tolist():\n",
    "        ensg_id = approved.loc[approved['symb'] == s, 'feature_id'].iloc[0]\n",
    "        if ensg_id in adata.var.index:\n",
    "            ensg_list.append(ensg_id)\n",
    "        else:\n",
    "            print(f'{s}/{ensg_id} not found in var')\n",
    "    else:\n",
    "        print(f'{s} not found in gene file')\n",
    "\n",
    "ensg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(adata, basis=default_embedding, color=ensg_list, use_raw=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare with the same genes using the raw counts to confirm they are correlated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(adata, basis=default_embedding, color=ensg_list, use_raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additionally, you could compare dotplots of those genes in each cell population**<br>\n",
    "*This will scale all genes based on the max range of any gene so 1 gene with high values may make others difficult to distinguish*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.dotplot(adata, ensg_list, 'cell_type_ontology_term_id', use_raw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.dotplot(adata, ensg_list, 'cell_type_ontology_term_id', use_raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_one = file + '_revised.h5ad'\n",
    "adata.write(filename=new_one, compression='gzip')\n",
    "new_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the CELLxGENE validator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_process = subprocess.run(['cellxgene-schema', 'validate', new_one], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "for line in validate_process.stdout.decode('utf-8').split('\\n'):\n",
    "    print(line)\n",
    "for line in validate_process.stderr.decode('utf-8').split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
