{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from cellxgene_mods import CxG_API\n",
    "\n",
    "\n",
    "CxG_API.config() # set env='dev' or 'staging' if working in either of those test environments\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf01cc5",
   "metadata": {},
   "source": [
    "**Specify the Collection to upload to**<br>\n",
    "If a Revision, use the Revision ID, not the Published ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091f9676",
   "metadata": {},
   "source": [
    "**List the existing Datasets in the Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02703f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_datasets = CxG_API.get_collection(collection_id)['datasets']\n",
    "status = {d['dataset_id']:d['processing_status'] for d in coll_datasets}\n",
    "titles = {d['dataset_id']:d['title'] for d in coll_datasets}\n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a9d56",
   "metadata": {},
   "source": [
    "**Set the directory that the files to upload are in**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3890758",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.expanduser('~/Downloads/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9e292e",
   "metadata": {},
   "source": [
    "**List certain files in that directory**<br>\n",
    "The curation_qa notebook saves files with a `_revised.h5ad` suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8dfa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in os.listdir(directory):\n",
    "    if f.endswith('_revised.h5ad') or f.endswith('fragments.tsv.gz'):\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c073beb0",
   "metadata": {},
   "source": [
    "**Fill in Dataset ID and file names to upload**<br>\n",
    "Use `new` for the _dataset_id_ if adding a Dataset, rather than replacing an existing Dataset\\\n",
    "_fragments_ is optional\\\n",
    "Use `existing` for _anndata_ if adding fragments to an existing Dataset without re-uploading the .h5ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159f2bde-5bcf-4430-967a-337ffe7e3bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    {\n",
    "        'dataset_id': '04a6b46d-138d-4cb0-b5a6-8cb85735590a',\n",
    "        'anndata': 'existing',\n",
    "        'fragments': directory + 'first_fragments.tsv.gz'\n",
    "    },\n",
    "    {\n",
    "        'dataset_id': 'new',\n",
    "        'anndata': directory + 'second_revised.h5ad',\n",
    "        'fragments': directory + 'second_fragments.tsv.gz'\n",
    "    },\n",
    "    {\n",
    "        'dataset_id': 'new',\n",
    "        'anndata': directory + 'third_revised.h5ad'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c021340-44b1-4f14-adc4-d0d4bbb4cce5",
   "metadata": {},
   "source": [
    "**Confirm the files are specified correctly, etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af7a164-816d-47e7-894d-d20d4e8d1927",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = [d['dataset_id'] for d in datasets]\n",
    "for index,d in enumerate(datasets):\n",
    "    if d['anndata'] != 'existing' and not os.path.exists(d['anndata']):\n",
    "        print(f\"Invalid file: {d['anndata']}\")\n",
    "    if 'fragments' in d and not os.path.exists(d['fragments']):\n",
    "        print(f\"Invalid file: {d['fragments']}\")\n",
    "    if d['anndata'] == 'existing':\n",
    "        if 'fragments' not in d:\n",
    "            print(f\"Must define fragments if revising an existing matrix for datasets[{index}]\")\n",
    "        if d['dataset_id'] == 'new':\n",
    "            print(f\"Must define either dataset_id or anndata file to upload for datasets[{index}]\")\n",
    "    if d['dataset_id'] != 'new':\n",
    "        if all_ids.count(d['dataset_id']) > 1:\n",
    "            print(f\"Repeated dataset: {d['dataset_id']}\")\n",
    "        if d['dataset_id'] not in titles:\n",
    "            print(f\"Invalid dataset: {d['dataset_id']}\")\n",
    "            continue\n",
    "        if status[d['dataset_id']] != 'SUCCESS':\n",
    "            print(f\"{d['dataset_id']} is processing_status:{status[d['dataset_id']]}, must wait for SUCCESS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c350ec5",
   "metadata": {},
   "source": [
    "**Upload each Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ead71-835e-4169-8fd9-a5d9c759f443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d in datasets:\n",
    "    if d['dataset_id'] == 'new':\n",
    "        d['dataset_id'] = CxG_API.create_dataset(collection_id)\n",
    "\n",
    "    if d['anndata'] == 'existing':\n",
    "        manifest = CxG_API.get_dataset_manifest(collection_id, d['dataset_id'])\n",
    "    else:\n",
    "        manifest = {\n",
    "            'anndata': CxG_API.upload_local_datafile(d['anndata'], collection_id, d['dataset_id'])\n",
    "        }\n",
    "\n",
    "    if 'fragments' in d:\n",
    "        manifest['atac_fragment'] = CxG_API.upload_local_datafile(d['fragments'], collection_id, d['dataset_id'])\n",
    "    \n",
    "    CxG_API.upload_datafiles_from_manifest(manifest, collection_id, d['dataset_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e9c048-3751-4953-a22a-2315cf78015d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
