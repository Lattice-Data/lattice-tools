{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0ce9fa-67de-4d0c-8507-dce2129d1029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from cellxgene_mods import CxG_API\n",
    "from datetime import datetime\n",
    "from pub_check import *\n",
    "\n",
    "\n",
    "CxG_API.config()\n",
    "\n",
    "pub_collections = CxG_API.get_collections()\n",
    "pub_dataset_ids = {d['dataset_id']:c['collection_id'] for c in pub_collections for d in c['datasets']}\n",
    "pub_collection_ids = [c['collection_id'] for c in pub_collections]\n",
    "\n",
    "priv_collections = CxG_API.get_collections(visibility='PRIVATE')\n",
    "priv_dataset_ids = {d['dataset_id']:c['collection_id'] for c in priv_collections for d in c['datasets']}\n",
    "priv_collection_ids = [c['collection_id'] for c in priv_collections]\n",
    "\n",
    "nonrev_priv_collections = [c for c in priv_collections if not c.get('revision_of')]\n",
    "\n",
    "ds_coll = {d['dataset_id']:c['collection_id'] for c in pub_collections + priv_collections for d in c['datasets']}\n",
    "\n",
    "wrk_dir = '/Users/jason/Downloads/'\n",
    "uuid_pattern = '[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522b477-aeb5-442b-ba52-8e38b1328440",
   "metadata": {},
   "source": [
    "# DOI review\n",
    "**check for preprints that have been published**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb4c8f-0174-42da-8f2c-b9f13abbf960",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_info = []\n",
    "for c in pub_collections + priv_collections:\n",
    "    if c.get('publisher_metadata') and c['publisher_metadata']['journal'] in ['bioRxiv', 'medRxiv']:\n",
    "        r = doi_checker(c['doi'])\n",
    "        pub_info.append(r)\n",
    "pub_df = pd.DataFrame(pub_info)\n",
    "if 'invalid DOI' in pub_df.columns:\n",
    "    display(pub_df[pub_df['invalid DOI'].isna() == False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bc6755-00e3-4a3f-b451-2f03f1d33eab",
   "metadata": {},
   "source": [
    "**check for Collections that might now have DOIs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac458f7d-f3e8-4627-91c1-10ffcd52e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2f75d249-1bec-459b-bf2b-b86221097ced is found in 10.24272/j.issn.2095-8137.2022.531 but this is reuse, not the data generation\n",
    "for c in pub_collections:\n",
    "    if not c.get('doi'):\n",
    "        dois = pubtator_search(c['collection_id'])\n",
    "        if dois:\n",
    "            print(c['collection_id'], ','.join(dois))\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4b563-2046-42d2-8164-350706dfb156",
   "metadata": {},
   "source": [
    "# long-term private Collections\n",
    "**pull private Collections older than a specified cut-off**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700c828-49f2-49bf-bc61-4e9f8eaeac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_cutoff = 1.5\n",
    "\n",
    "day_cutoff = 365.25 * year_cutoff\n",
    "today = datetime.today()\n",
    "\n",
    "sorted_collections = sorted(nonrev_priv_collections, key=lambda nonrev_priv_collections: nonrev_priv_collections['created_at'])\n",
    "\n",
    "f = open(f'{wrk_dir}long_private_collections.csv', 'w', encoding='UTF8')\n",
    "\n",
    "writer = csv.writer(f)\n",
    "writer.writerow([\n",
    "    'collection',\n",
    "    'name',\n",
    "    'doi',\n",
    "    'contact name',\n",
    "    'contact email',\n",
    "    'created at',\n",
    "    'number of datasets'\n",
    "])\n",
    "\n",
    "for collection in sorted_collections:\n",
    "    date1 = datetime.strptime(collection['created_at'].split('T')[0], '%Y-%m-%d')\n",
    "    difference = today - date1\n",
    "    gap = difference.days\n",
    "\n",
    "    if gap > day_cutoff:\n",
    "        writer.writerow([\n",
    "            collection['collection_url'],\n",
    "            collection['name'],\n",
    "            collection['doi'],\n",
    "            collection['contact_name'],\n",
    "            collection['contact_email'],                \n",
    "            collection['created_at'],\n",
    "            len(collection['datasets'])\n",
    "        ])\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09a0c47-faa9-4e62-83ad-2b6ae81f5d3f",
   "metadata": {},
   "source": [
    "# private URLs made public\n",
    "**looked for private Collection URLs in PubMed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266a3ed-20d2-4372-a8e7-038cd0f73106",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubtator_res = []\n",
    "for c in priv_collection_ids:\n",
    "    dois = pubtator_search(c)\n",
    "    if dois:\n",
    "        new = {'collection_id':c, 'source': ','.join(dois)}\n",
    "        pubtator_res.append(new)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede2167a-a059-4e71-9da7-1359e52fa758",
   "metadata": {},
   "source": [
    "**filter AirTable report for possible private URL sharing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab134a9-aaf3-414a-9596-ef54fea23701",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_export = 'Sources of private collections_datasets-Grid view.csv'\n",
    "df = pd.read_csv(f'{wrk_dir}{at_export}')\n",
    "\n",
    "month = df.loc[0]['time period']\n",
    "ignore_sources = ['lattice.atlassian.net','lattice-data.org','Direct / None']\n",
    "\n",
    "df = df[\n",
    "    (df['time period'] == month) &\n",
    "    (df['source'].isin(ignore_sources) == False) &\n",
    "    (df['url'].str.contains(uuid_pattern))\n",
    "]\n",
    "df.drop(columns=['dataset name','time period'], inplace=True)\n",
    "\n",
    "act = df[df['url'].str.startswith('/collections/')]\n",
    "act['collection_id'] = act['url'].apply(lambda x: x.split('/')[2])\n",
    "act = act[act['collection_id'].isin(priv_collection_ids)]\n",
    "\n",
    "ds_df = df[df['url'].str.startswith('/e/')]\n",
    "ds_df['dataset_id'] = ds_df['url'].apply(lambda x: x.split('/')[2].split('.')[0])\n",
    "ds_df = ds_df[ds_df['dataset_id'].isin(priv_dataset_ids.keys())]\n",
    "ds_df['collection_id'] = ds_df['dataset_id'].map(ds_coll)\n",
    "\n",
    "act = pd.concat([act, ds_df, pd.DataFrame(pubtator_res)]).fillna({'visitors':0, 'dataset_id': ''})\n",
    "act = act.groupby('collection_id').agg({\n",
    "    'source': lambda x: ','.join(set(x)),\n",
    "    'dataset_id': lambda x: ','.join(set(x)).strip(','),\n",
    "    'visitors': 'sum'\n",
    "}).sort_values('visitors', ascending=False)\n",
    "act.reset_index(inplace=True)\n",
    "act['collection_url'] = 'https://cellxgene.cziscience.com/collections/' + act['collection_id'].astype(str)\n",
    "act = act[['collection_url','source','visitors','dataset_id']]\n",
    "\n",
    "act.to_csv(f'{wrk_dir}private_URL_{month}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec310a96-a5a5-4ace-ae50-1ee35abbdc17",
   "metadata": {},
   "source": [
    "# is_primary_data evaluation\n",
    "**read in the Sheets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14814163-7669-46e5-9abd-9778c75089e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = '1ax9b5sxmxSJgrjncXG5WGilgIGKm2EEWmILpoN6pLzY'\n",
    "\n",
    "tab = 'primary'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet}/gviz/tq?tqx=out:csv&sheet={tab}'\n",
    "pri_df = pd.read_csv(url)\n",
    "pri_df = pri_df[[c for c in pri_df.columns if 'Unnamed' not in c]]\n",
    "\n",
    "tab = 'reused'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet}/gviz/tq?tqx=out:csv&sheet={tab}'\n",
    "reuse_df = pd.read_csv(url)\n",
    "reuse_df = reuse_df[[c for c in reuse_df.columns if 'Unnamed' not in c]]\n",
    "\n",
    "#probably need to isolate the published reused (away from the in progress jira tickets)\n",
    "pub_reuse_df = reuse_df[\n",
    "    (reuse_df['dataset'].str.startswith('CXG-') == False) &\n",
    "    (reuse_df['dataset'].str.startswith('WRN-') == False)\n",
    "]\n",
    "\n",
    "#Confirm that all Collection IDs are valid\n",
    "invalid_coll_id = [c for c in set(pri_df['collection'].tolist() + pub_reuse_df['collection'].tolist()) if c not in pub_collection_ids]\n",
    "if invalid_coll_id:\n",
    "    print('Invalid Collection IDs',invalid_coll_id)\n",
    "\n",
    "#Confirm that Dataset IDs are found in the corresponding Collection (reused tab)\n",
    "for i,row in pub_reuse_df[['dataset','collection']].drop_duplicates().iterrows():\n",
    "    if row['dataset'] not in pub_dataset_ids:\n",
    "        print('Invalid Dataset ID', row['dataset'])\n",
    "    elif row['collection'] != pub_dataset_ids[row['dataset']]:\n",
    "        print('Invalid Dataset/Collection pairing',row['dataset_id'],row['collection_id'])\n",
    "\n",
    "#Confirm that all Published Collections are represented in the primary tab\n",
    "missing = [c for c in pub_collection_ids if c not in pri_df['collection'].tolist()]\n",
    "if missing:\n",
    "    print('Add to primary tab', missing)\n",
    "    \n",
    "#Any primary tab w/ \"NA\" should have all cells accounted for in reused tab\n",
    "for collection_id in pri_df[pri_df['original data is_primary_data'].isna()]['collection'].unique():\n",
    "    if collection_id not in pub_reuse_df['collection'].unique():\n",
    "        print('Collection annotated as no original data generated, but no reuse noted',collection_id)\n",
    "\n",
    "#check that any n/a do not have DOIs in the reused tab (no original data to reuse)\n",
    "for doi in pri_df[pri_df['original data is_primary_data'].isna()]['DOI'].unique():\n",
    "    if doi in reuse_df['DOI'].unique():\n",
    "        print('DOI annotated as no original data generated, but marked as reused',doi)\n",
    "\n",
    "#Any primary tab w/ \"FALSE\" should have some accounted for in reused tab as TRUE\n",
    "for doi in pri_df[pri_df['original data is_primary_data'] == False]['DOI'].unique():\n",
    "    if doi not in pub_reuse_df[pub_reuse_df['is_primary_data'] == True]['DOI'].unique():\n",
    "        print('DOI is FALSE in primary Collection, but no TRUE reuse accounted for',doi)\n",
    "\n",
    "#ATTN - Fill in empty feature_count? Validate feature_count?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7dc93-1200-4aae-a9d5-7e07a2ed9e21",
   "metadata": {},
   "source": [
    "**Check that reused obs are accurately annotated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e208167-793f-4742-90d4-0c2c6452ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for dataset_id in pub_reuse_df['dataset'].unique():\n",
    "    ds_df = pub_reuse_df[pub_reuse_df['dataset'] == dataset_id]\n",
    "    reused_obs_indices = []\n",
    "    #ATTN - obs is this thing\n",
    "    for i,row in ds_df.iterrows():\n",
    "        prop = row['obs field']\n",
    "        if prop not in obs.columns and prop != 'all':\n",
    "            row['error'] = 'obs field not in obs'\n",
    "            errors.append(row)\n",
    "        else:\n",
    "            values = row['obs field values'].split(',') if not pd.isna(row['obs field values']) else None\n",
    "            obs_count = row['observation count']\n",
    "            if prop == 'all':\n",
    "                obs_by_this_row = obs\n",
    "                if values:\n",
    "                    row['errors'] = 'obs field:\"all\" should not have values annotated'\n",
    "                    errors.append(row)\n",
    "            else:\n",
    "                not_in_obs = [v for v in values if v not in obs[prop].unique()]\n",
    "                if not_in_obs:\n",
    "                    row['error'] = 'value not in obs column'\n",
    "                    errors.append(row)\n",
    "                obs_by_this_row = obs[obs[prop].isin(values)]\n",
    "\n",
    "            if obs_by_this_row.shape[0] != obs_count:\n",
    "                row['error'] = f\"inconsistent cell count {obs_count} vs {obs_by_this_row.shape[0]}\"\n",
    "                errors.append(row)\n",
    "\n",
    "            if list(obs_by_this_row['is_primary_data'].unique()) != row['is_primary_data']:\n",
    "                row['error'] = 'inconsistent is_primary_data'\n",
    "                errors.append(row)\n",
    "    \n",
    "            reused_obs_indices.extend(obs_by_this_row.index)\n",
    "    if len(reused_obs_indices) != len(set(reused_obs_indices)):\n",
    "        #dup_indices = [i for i in reused_obs_indices if reused_obs_indices.count(i) > 1]\n",
    "        print('Overlapping reused data',dataset_id)\n",
    "pd.DataFrame(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32480a2f-b153-416b-a4a8-0018aa4b2e4b",
   "metadata": {},
   "source": [
    "**Check all DOIs in the sheet to confirm they are valid & up-to-date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf6c79-7b36-4295-8984-62b7028c3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_info = []\n",
    "for doi in set(list(pri_df['DOI'].unique()) + list(reuse_df['DOI'].unique())):\n",
    "    r = doi_checker(doi)\n",
    "    pub_info.append(r)\n",
    "pub_df = pd.DataFrame(pub_info)\n",
    "if 'invalid DOI' in pub_df.columns:\n",
    "    display(pub_df[pub_df['invalid DOI'].isna() == False].sort_values('DOI'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb69c9-4501-43ba-8c5e-a45bafdf6cf4",
   "metadata": {},
   "source": [
    "**Check for DOIs that are marked `True` in multiple places**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedeecde-fbcb-41da-bced-2447b3a95019",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_pri_df = pd.concat([\n",
    "    pub_reuse_df[pub_reuse_df['is_primary_data'] == True][['DOI','is_primary_data']],\n",
    "    pri_df[pri_df['original data is_primary_data'] == True][['DOI','original data is_primary_data']]\n",
    "])\n",
    "#ATTN - THINK THIS WILL FLAG DOI REUSED & PRIMARY IN MULTIPLE DATASETS WITHIN 1 COLLECTION\n",
    "comb_pri_df[\n",
    "    (comb_pri_df.duplicated(subset='DOI', keep=False)) &\n",
    "    (comb_pri_df['DOI'].isna() == False)\n",
    "].sort_values('DOI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8f1ef6-024a-4d08-862e-98f88c5c331a",
   "metadata": {},
   "source": [
    "**Check for DOIs that are not marked `True` anywhere**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ccef3-6d11-4ee6-8752-24ae17072a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all DOIs that are not is_primary_data TRUE anywhere\n",
    "comb_nonpri_df = pd.concat([\n",
    "    pub_reuse_df[pub_reuse_df['is_primary_data'] == False][['DOI','is_primary_data']],\n",
    "    pri_df[pri_df['original data is_primary_data'] == False][['DOI','original data is_primary_data']]\n",
    "])\n",
    "\n",
    "comb_nonpri_df[comb_nonpri_df['DOI'].isin(comb_pri_df['DOI'].unique()) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8114c2-9d65-488d-af87-cb1165d4fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPARE ALL INSTANCES OF DOIs PRESENT MULTIPLE TIMES\n",
    "#OBS COUNT\n",
    "#FEATURE COUNT\n",
    "#FEATURE REFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd30bd7-135f-4125-9fdc-130acecef447",
   "metadata": {},
   "source": [
    "# in progress DOIs\n",
    "**generate a report of DOIs currently in private Collections**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c658f56b-cfc8-4b50-9912-fc8db28b0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = today.strftime('%Y_%m_%d')\n",
    "priv_dois = set([\n",
    "    c['doi'] for c in nonrev_priv_collections if c.get('doi')\n",
    "])\n",
    "filename = f'{wrk_dir}cxg_private_dois_{date}.txt'\n",
    "with open(filename, 'w') as file:\n",
    "    for doi in priv_dois:\n",
    "        file.write(f'{doi}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34630cfd-0304-4242-a9fc-71ca6198278e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
