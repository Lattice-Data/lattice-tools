{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0ce9fa-67de-4d0c-8507-dce2129d1029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import csv\n",
    "import fsspec\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "from cellxgene_mods import CxG_API\n",
    "from datetime import datetime\n",
    "from urllib.parse import quote\n",
    "\n",
    "sys.path.append('..')\n",
    "from public_resources.public_resources import doi_checker,pubtator_search\n",
    "\n",
    "\n",
    "CxG_API.config()\n",
    "fs = fsspec.filesystem('s3')\n",
    "today = datetime.today()\n",
    "\n",
    "pub_collections = CxG_API.get_collections()\n",
    "pub_dataset_ids = {d['dataset_id']:c['collection_id'] for c in pub_collections for d in c['datasets']}\n",
    "pub_collection_ids = [c['collection_id'] for c in pub_collections]\n",
    "pub_collection_dois = {c['collection_id']:c['doi'] for c in pub_collections}\n",
    "pub_dataset_ver_ids = {d['dataset_id']:d['dataset_version_id'] for c in pub_collections for d in c['datasets']}\n",
    "\n",
    "priv_collections = CxG_API.get_collections(visibility='PRIVATE')\n",
    "priv_dataset_ids = {d['dataset_id']:c['collection_id'] for c in priv_collections for d in c['datasets']}\n",
    "priv_collection_ids = [c['collection_id'] for c in priv_collections]\n",
    "\n",
    "nonrev_priv_collections = [c for c in priv_collections if not c.get('revision_of')]\n",
    "\n",
    "ds_coll = {d['dataset_id']:c['collection_id'] for c in pub_collections + priv_collections for d in c['datasets']}\n",
    "\n",
    "\n",
    "sheet = '1ax9b5sxmxSJgrjncXG5WGilgIGKm2EEWmILpoN6pLzY'\n",
    "\n",
    "tab = 'published Collection DOIs'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet}/gviz/tq?tqx=out:csv&sheet={quote(tab)}'\n",
    "pri_df = pd.read_csv(url)\n",
    "pri_df = pri_df[[c for c in pri_df.columns if 'Unnamed' not in c]]\n",
    "\n",
    "tab = 'reused data'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet}/gviz/tq?tqx=out:csv&sheet={quote(tab)}'\n",
    "reuse_df = pd.read_csv(url)\n",
    "reuse_df = reuse_df[[c for c in reuse_df.columns if 'Unnamed' not in c]]\n",
    "\n",
    "pub_reuse_df = reuse_df[\n",
    "    (reuse_df['Dataset'].str.startswith('CXG-') == False) &\n",
    "    (reuse_df['Dataset'].str.startswith('WRN-') == False)\n",
    "]\n",
    "\n",
    "\n",
    "uuid_pattern = '[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}'\n",
    "outpre = 'CxGmonthly'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522b477-aeb5-442b-ba52-8e38b1328440",
   "metadata": {},
   "source": [
    "# DOI review\n",
    "**check for preprints that have been published**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb4c8f-0174-42da-8f2c-b9f13abbf960",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_info = []\n",
    "for c in pub_collections + priv_collections:\n",
    "    if c.get('publisher_metadata') and c['publisher_metadata']['journal'] in ['bioRxiv', 'medRxiv']:\n",
    "        r = doi_checker(c['doi'])\n",
    "        pub_info.append(r)\n",
    "pub_df = pd.DataFrame(pub_info)\n",
    "if 'invalid DOI' in pub_df.columns:\n",
    "    display(pub_df[pub_df['invalid DOI'].isna() == False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bc6755-00e3-4a3f-b451-2f03f1d33eab",
   "metadata": {},
   "source": [
    "**check for Collections that might now have DOIs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac458f7d-f3e8-4627-91c1-10ffcd52e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = {\n",
    "    '2f75d249-1bec-459b-bf2b-b86221097ced': [\n",
    "        '10.24272/j.issn.2095-8137.2022.531' #reuse, not data generation\n",
    "    ],\n",
    "    'a98b828a-622a-483a-80e0-15703678befd': [\n",
    "        '10.64898/2026.01.06.698060' #reuse, not data generation\n",
    "    ]\n",
    "}\n",
    "\n",
    "for c in pub_collections:\n",
    "    if not c.get('doi'):\n",
    "        dois = pubtator_search(c['collection_id'])\n",
    "        for d in dois:\n",
    "            if d not in ok.get(c['collection_id'], []):\n",
    "                print(c['collection_id'], d)\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4b563-2046-42d2-8164-350706dfb156",
   "metadata": {},
   "source": [
    "# long-term private Collections\n",
    "**pull private Collections older than a specified cut-off**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700c828-49f2-49bf-bc61-4e9f8eaeac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_cutoff = 1.5\n",
    "\n",
    "day_cutoff = 365.25 * year_cutoff\n",
    "\n",
    "sorted_collections = sorted(nonrev_priv_collections, key=lambda nonrev_priv_collections: nonrev_priv_collections['created_at'])\n",
    "\n",
    "f = open(f'{outpre}_long_private_collections.csv', 'w', encoding='UTF8')\n",
    "\n",
    "writer = csv.writer(f)\n",
    "writer.writerow([\n",
    "    'collection',\n",
    "    'name',\n",
    "    'doi',\n",
    "    'contact name',\n",
    "    'contact email',\n",
    "    'created at',\n",
    "    'number of datasets'\n",
    "])\n",
    "\n",
    "for collection in sorted_collections:\n",
    "    date1 = datetime.strptime(collection['created_at'].split('T')[0], '%Y-%m-%d')\n",
    "    difference = today - date1\n",
    "    gap = difference.days\n",
    "\n",
    "    if gap > day_cutoff:\n",
    "        writer.writerow([\n",
    "            collection['collection_url'],\n",
    "            collection['name'],\n",
    "            collection['doi'],\n",
    "            collection['contact_name'],\n",
    "            collection['contact_email'],                \n",
    "            collection['created_at'],\n",
    "            len(collection['datasets'])\n",
    "        ])\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09a0c47-faa9-4e62-83ad-2b6ae81f5d3f",
   "metadata": {},
   "source": [
    "# private URLs made public\n",
    "**looked for private Collection URLs in PubMed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266a3ed-20d2-4372-a8e7-038cd0f73106",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubtator_res = []\n",
    "for c in priv_collection_ids:\n",
    "    dois = pubtator_search(c)\n",
    "    if dois:\n",
    "        new = {'collection_id':c, 'source': ','.join(dois)}\n",
    "        pubtator_res.append(new)\n",
    "    time.sleep(0.5)\n",
    "pubtator_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede2167a-a059-4e71-9da7-1359e52fa758",
   "metadata": {},
   "source": [
    "**filter AirTable report for possible private URL sharing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab134a9-aaf3-414a-9596-ef54fea23701",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_export = 'Sources of private collections_datasets-Grid view.csv'\n",
    "df = pd.read_csv(at_export)\n",
    "\n",
    "month = df.loc[0]['time period']\n",
    "ignore_sources = ['lattice.atlassian.net','lattice-data.org','Direct / None']\n",
    "\n",
    "df = df[\n",
    "    (df['time period'] == month) &\n",
    "    (df['source'].isin(ignore_sources) == False) &\n",
    "    (df['url'].str.contains(uuid_pattern))\n",
    "]\n",
    "df.drop(columns=['dataset name','time period'], inplace=True)\n",
    "\n",
    "act = df[df['url'].str.startswith('/collections/')]\n",
    "act['collection_id'] = act['url'].apply(lambda x: x.split('/')[2])\n",
    "act = act[act['collection_id'].isin(priv_collection_ids)]\n",
    "\n",
    "ds_df = df[df['url'].str.startswith('/e/')]\n",
    "ds_df['dataset_id'] = ds_df['url'].apply(lambda x: x.split('/')[2].split('.')[0])\n",
    "ds_df = ds_df[ds_df['dataset_id'].isin(priv_dataset_ids.keys())]\n",
    "ds_df['collection_id'] = ds_df['dataset_id'].map(ds_coll)\n",
    "\n",
    "act = pd.concat([act, ds_df, pd.DataFrame(pubtator_res)]).fillna({'visitors':0, 'dataset_id': ''})\n",
    "act = act.groupby('collection_id').agg({\n",
    "    'source': lambda x: ','.join(set(x)),\n",
    "    'dataset_id': lambda x: ','.join(set(x)).strip(','),\n",
    "    'visitors': 'sum'\n",
    "}).sort_values('visitors', ascending=False)\n",
    "act.reset_index(inplace=True)\n",
    "act['collection_url'] = 'https://cellxgene.cziscience.com/collections/' + act['collection_id'].astype(str)\n",
    "act = act[['collection_url','source','visitors','dataset_id']]\n",
    "\n",
    "act.to_csv(f'{outpre}_private_URL.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec310a96-a5a5-4ace-ae50-1ee35abbdc17",
   "metadata": {},
   "source": [
    "# is_primary_data evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14814163-7669-46e5-9abd-9778c75089e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm that all Collection IDs are valid\n",
    "invalid_coll_id = [c for c in set(pri_df['Collection'].tolist() + pub_reuse_df['Collection'].tolist()) if c not in pub_collection_ids]\n",
    "if invalid_coll_id:\n",
    "    print('Invalid Collection IDs',invalid_coll_id)\n",
    "\n",
    "#Confirm that all Collection IDs have the appropriate DOI documented in the table\n",
    "for i,row in pri_df[['Collection','DOI of Collection']].iterrows():\n",
    "    if row['Collection'] not in invalid_coll_id:\n",
    "        if pub_collection_dois[row['Collection']] and row['DOI of Collection'] != pub_collection_dois[row['Collection']]:\n",
    "            print('DOI not up-to-date',row['Collection'])\n",
    "\n",
    "#Confirm that Dataset IDs are found in the corresponding Collection (reused tab)\n",
    "for i,row in pub_reuse_df[['Dataset','Collection']].drop_duplicates().iterrows():\n",
    "    if row['Dataset'] not in pub_dataset_ids:\n",
    "        print('Invalid Dataset ID', row['Dataset'])\n",
    "    elif row['Collection'] != pub_dataset_ids[row['Dataset']]:\n",
    "        print('Invalid Dataset/Collection pairing',row['Dataset'],row['Collection'])\n",
    "\n",
    "#Confirm that all Published Collections are represented in the primary tab\n",
    "missing = [c for c in pub_collection_ids if c not in pri_df['Collection'].tolist()]\n",
    "if missing:\n",
    "    print('Add to primary tab', missing)\n",
    "\n",
    "#Any primary tab w/ \"NA\" should have all cells accounted for in reused tab\n",
    "for collection_id in pri_df[pri_df['original data is_primary_data'].isna()]['Collection'].unique():\n",
    "    if collection_id not in pub_reuse_df['Collection'].unique():\n",
    "        print('Collection annotated as no original data generated, but no reuse noted',collection_id)\n",
    "\n",
    "#check that any n/a do not have DOIs in the reused tab (no original data to reuse)\n",
    "for doi in pri_df[pri_df['original data is_primary_data'].isna()]['DOI of Collection'].unique():\n",
    "    if doi in reuse_df['DOI of reused data'].unique():\n",
    "        print('DOI annotated as no original data generated, but marked as reused',doi)\n",
    "\n",
    "#Any primary tab w/ \"FALSE\" should have some accounted for in reused tab as TRUE\n",
    "for i,row in pri_df[pri_df['original data is_primary_data'] == False].iterrows():\n",
    "    doi = row['DOI of Collection']\n",
    "    url = 'https://cellxgene.cziscience.com/collections/' + row['Collection']\n",
    "    if doi not in pub_reuse_df[pub_reuse_df['is_primary_data'] == True]['DOI of reused data'].unique():\n",
    "        if url not in pub_reuse_df[pub_reuse_df['is_primary_data'] == True]['DOI of reused data'].unique():\n",
    "            print('DOI is FALSE in primary Collection, but no TRUE reuse accounted for', row['Collection'])\n",
    "\n",
    "#Fill in empty feature_count\n",
    "for i,row in pub_reuse_df[pub_reuse_df['Feature count'].isna()][['Collection','Dataset']].drop_duplicates().iterrows():\n",
    "    ds = CxG_API.get_dataset(row['Collection'],row['Dataset'])\n",
    "    print('Feature counts:',row['Dataset'],ds['feature_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7dc93-1200-4aae-a9d5-7e07a2ed9e21",
   "metadata": {},
   "source": [
    "**Check that reused obs are accurately annotated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e208167-793f-4742-90d4-0c2c6452ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for dataset_id in pub_reuse_df['Dataset'].unique():\n",
    "    ds_df = pub_reuse_df[pub_reuse_df['Dataset'] == dataset_id]\n",
    "    reused_obs_indices = []\n",
    "\n",
    "    dataset_version_id = pub_dataset_ver_ids[dataset_id]\n",
    "    with h5py.File(fs.open(f'corpora-data-prod/{dataset_version_id}/local.h5ad')) as f:\n",
    "        obs = ad.io.read_elem(f['obs'])\n",
    "\n",
    "    for i,row in ds_df.iterrows():\n",
    "        prop = row['obs field']\n",
    "        if prop not in obs.columns and prop != 'all':\n",
    "            row['error'] = 'obs field not in obs'\n",
    "            errors.append(row)\n",
    "            continue\n",
    "        else:\n",
    "            values = row['obs field values'].split(',') if not pd.isna(row['obs field values']) else None\n",
    "            obs_count = row['observation count']\n",
    "            if prop == 'all':\n",
    "                obs_by_this_row = obs\n",
    "                if values:\n",
    "                    row['errors'] = 'obs field:\"all\" should not have values annotated'\n",
    "                    errors.append(row)\n",
    "                    continue\n",
    "            else:\n",
    "                not_in_obs = [v for v in values if v not in obs[prop].unique()]\n",
    "                if not_in_obs:\n",
    "                    row['error'] = 'value not in obs column'\n",
    "                    errors.append(row)\n",
    "                    continue\n",
    "                obs_by_this_row = obs[obs[prop].isin(values)]\n",
    "\n",
    "            if obs_by_this_row.shape[0] != obs_count:\n",
    "                row['error'] = f'inconsistent cell count {obs_count} vs {obs_by_this_row.shape[0]}'\n",
    "                errors.append(row)\n",
    "                continue\n",
    "\n",
    "            if list(obs_by_this_row['is_primary_data'].unique()) != [row['is_primary_data']]:\n",
    "                row['error'] = 'inconsistent is_primary_data'\n",
    "                errors.append(row)\n",
    "                continue\n",
    "    \n",
    "            reused_obs_indices.extend(obs_by_this_row.index)\n",
    "    if len(reused_obs_indices) != len(set(reused_obs_indices)):\n",
    "        print('Overlapping reused data',dataset_id)\n",
    "pd.DataFrame(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32480a2f-b153-416b-a4a8-0018aa4b2e4b",
   "metadata": {},
   "source": [
    "**Check all DOIs in the sheet to confirm they are valid & up-to-date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf6c79-7b36-4295-8984-62b7028c3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_info = []\n",
    "for doi in set(list(pri_df['DOI of Collection'].unique()) + list(reuse_df['DOI of reused data'].unique())):\n",
    "    r = doi_checker(doi)\n",
    "    pub_info.append(r)\n",
    "pub_df = pd.DataFrame(pub_info)\n",
    "if 'invalid DOI' in pub_df.columns:\n",
    "    display(pub_df[pub_df['invalid DOI'].isna() == False].sort_values('DOI'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb69c9-4501-43ba-8c5e-a45bafdf6cf4",
   "metadata": {},
   "source": [
    "**Check for DOIs that are marked `True` in multiple places**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1828870b-6a5c-438c-91f1-d2202c7b7d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = {\n",
    "    '10.1002/hep4.1854': [ #1 Visium slide in a 2ry Collection\n",
    "        '0c8a364b-97b5-4cc8-a593-23c38c6f0ac5','44531dd9-1388-4416-a117-af0a99de2294'\n",
    "    ],\n",
    "    '10.1038/s41467-018-06318-7': [ #4 donors in a 2ry Collection, 1 donor in another 2ry Collection\n",
    "        '0c8a364b-97b5-4cc8-a593-23c38c6f0ac5','44531dd9-1388-4416-a117-af0a99de2294'\n",
    "    ],\n",
    "    '10.1038/s41467-024-49037-y': [ #mouse & human in separate Collections\n",
    "        '67ba665e-0611-4b53-a522-40c2e0dc6df7','71f4bccf-53d4-4c12-9e80-e73bfb89e398'\n",
    "    ],\n",
    "    '10.1101/2020.11.20.20227355': [ #2 studies from 1 preprint\n",
    "        '0434a9d4-85fd-4554-b8e3-cf6c582bb2fa','eb735cc9-d0a7-48fa-b255-db726bf365af'\n",
    "    ],\n",
    "    '10.1016/j.devcel.2020.11.010': [ #organoid data in a 2ry Collection\n",
    "        '6282a908-f162-44a2-99a3-8a942e4271b2','17481d16-ee44-49e5-bcf0-28c0780d8c4a'\n",
    "    ],\n",
    "    '10.1016/j.cell.2021.04.028': [ #organoid data in a 2ry Collection\n",
    "        '6282a908-f162-44a2-99a3-8a942e4271b2','dfc09a93-bce0-4c77-893d-e153d1b7f9fa'\n",
    "    ],\n",
    "    '10.1016/j.devcel.2020.01.033': [ #organoid data & tissue data in separate 2ry Collections\n",
    "        '6282a908-f162-44a2-99a3-8a942e4271b2','dfc09a93-bce0-4c77-893d-e153d1b7f9fa'\n",
    "    ],\n",
    "    '10.1016/j.devcel.2020.07.023': [ #organoid data & tissue data in separate 2ry Collections\n",
    "        '6282a908-f162-44a2-99a3-8a942e4271b2','dfc09a93-bce0-4c77-893d-e153d1b7f9fa'\n",
    "    ],\n",
    "    '10.1016/j.stem.2020.11.008': [ #organoid data & tissue data in separate 2ry Collections\n",
    "        '6282a908-f162-44a2-99a3-8a942e4271b2','dfc09a93-bce0-4c77-893d-e153d1b7f9fa'\n",
    "    ],\n",
    "    '10.1038/s41586-019-1373-2': [ #organoid data & tissue data in separate 2ry Collections\n",
    "        '6282a908-f162-44a2-99a3-8a942e4271b2','854c0855-23ad-4362-8b77-6b1639e7a9fc'\n",
    "    ],\n",
    "    '10.1016/j.molmet.2022.101595': [ #mouse data is is_primary_data:False in the 1ry Collection\n",
    "        '296237e2-393d-4e31-b590-b03f74ac5070', '0a77d4c0-d5d0-40f0-aa1a-5e1429bcbd7e'\n",
    "    ],\n",
    "    '10.1038/s41467-021-25968-8': [ #different tissues in separate 2ry Collections\n",
    "        '0f7d022a-46c7-4e64-be4c-e34adbb78089', '48c15b0c-6039-4e0f-9668-b6b3c0b830ad'\n",
    "    ],\n",
    "    '10.1038/s41586-025-09686-5': [ #2 studies from 1 publication\n",
    "        '77f9d7e9-5675-49c3-abed-ce02f39eef1b', 'e9360edf-b0b7-4e01-bce8-e596814f13e7'\n",
    "    ],\n",
    "    '10.15252/embj.2020107333': [ #normal data & disease data in separate 2ry Collections\n",
    "        '48259aa8-f168-4bf5-b797-af8e88da6637', '9432ae97-4803-4b9f-8f64-2b41e42ad3cb'\n",
    "    ],\n",
    "    '10.1038/s41586-025-09686-5': [ #3 different cohorts in separate Collections\n",
    "        '77f9d7e9-5675-49c3-abed-ce02f39eef1b', '60a2676d-9f37-46cc-9b02-c7370a53be9c', 'e9360edf-b0b7-4e01-bce8-e596814f13e7'\n",
    "    ]\n",
    "}\n",
    "\n",
    "comb_pri_df = pd.concat([\n",
    "    pub_reuse_df[pub_reuse_df['is_primary_data'] == True].rename(columns={'DOI of reused data':'DOI'})[['DOI','is_primary_data','Collection']],\n",
    "    pri_df[pri_df['original data is_primary_data'] == True].rename(columns={'DOI of Collection':'DOI'})[['DOI','original data is_primary_data','Collection']]\n",
    "])\n",
    "\n",
    "poss_dup_true = comb_pri_df\n",
    "poss_dup_true['doi_coll'] = comb_pri_df.apply(lambda x: f\"{x['DOI']}{x['Collection']}\", axis=1)\n",
    "poss_dup_true.drop_duplicates(inplace=True)\n",
    "poss_dup_true.drop(columns='doi_coll', inplace=True)\n",
    "\n",
    "poss_dup_true = poss_dup_true[\n",
    "    (poss_dup_true.duplicated(subset='DOI', keep=False)) &\n",
    "    (poss_dup_true['DOI'].isna() == False)\n",
    "]\n",
    "\n",
    "ok_list = []\n",
    "for doi in poss_dup_true['DOI'].unique():\n",
    "    if doi in ok:\n",
    "        collections_in_table = poss_dup_true[poss_dup_true['DOI'] == doi]['Collection'].unique()\n",
    "        if set(collections_in_table) == set(ok[doi]):\n",
    "            ok_list.append(doi)\n",
    "\n",
    "poss_dup_true[poss_dup_true['DOI'].isin(ok_list) == False].sort_values('DOI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8f1ef6-024a-4d08-862e-98f88c5c331a",
   "metadata": {},
   "source": [
    "**Check for DOIs that are not marked `True` anywhere**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ccef3-6d11-4ee6-8752-24ae17072a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_nonpri_df = pd.concat([\n",
    "    pub_reuse_df[pub_reuse_df['is_primary_data'] == False].rename(columns={'DOI of reused data':'DOI'})[['DOI','is_primary_data']],\n",
    "    pri_df[pri_df['original data is_primary_data'] == False].rename(columns={'DOI of Collection':'DOI'})[['DOI','original data is_primary_data']]\n",
    "])\n",
    "\n",
    "comb_nonpri_df[comb_nonpri_df['DOI'].isin(comb_pri_df['DOI'].unique()) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ba9767-74d8-4dc7-8926-847f444ac3c5",
   "metadata": {},
   "source": [
    "**IN PROGRESS - Compare instances of each DOI that is present multiple places**\n",
    "- obs count\n",
    "- feature count\n",
    "- feature reference\n",
    "\n",
    "**Determine which should be `True`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34630cfd-0304-4242-a9fc-71ca6198278e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
