{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6d908-5bdb-483c-b9b3-47fd8e1bf20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import subprocess\n",
    "from anndata._io.specs import read_elem\n",
    "\n",
    "\n",
    "barcode_pattern = r'[ACGT]{16}'\n",
    "replace_with = 'B@RCODE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a00e8-bc60-4629-ab31-4be05617b317",
   "metadata": {},
   "source": [
    "**Define the directory that contains the AnnData file and the unfiltered fragments files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dbcc35-c7fd-43ba-ada6-12eee03b5f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dir = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465e290f-c5c7-48ab-898e-ded21864516b",
   "metadata": {},
   "source": [
    "**Read in the barcodes from the AnnData & extract each prefix/suffix**\\\n",
    "These will be the values in `id_map` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe05622-5354-4ec3-9d7b-4abfe1c37bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_file = ''\n",
    "with h5py.File(f'{my_dir}{mx_file}') as f:\n",
    "    barcodes = read_elem(f['obs']).index.to_series()\n",
    "index_patterns = set([re.sub(barcode_pattern, replace_with, b) for b in barcodes])\n",
    "index_patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416cea33-b049-42a7-a674-a17f99ae5adc",
   "metadata": {},
   "source": [
    "**Define the ending that is expected on each unfiltered fragments files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b846f08-1db4-45c7-b5b3-ad142e2106f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_end = 'atac_fragments.tsv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424499b-ef8d-427e-9ab4-98fef6fe3fd0",
   "metadata": {},
   "source": [
    "**Extract the library IDs in the names of the raw fragments files**\\\n",
    "These will be the keys in `id_map` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444adce-bf7c-4d7c-b003-7eaeb959338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ids = [f.replace(file_end,'') for f in os.listdir(my_dir) if f.endswith(file_end)]\n",
    "file_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5f953b-5aaa-4240-b7f2-919d55d93075",
   "metadata": {},
   "source": [
    "**Map the file library IDs to the library IDs with the barcodes in the RNA file index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cefa94-2090-4652-98cd-f7764d73acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = {\n",
    "    'G120_F1_N_': 'B@RCODE-1_1',\n",
    "    'G133_D_FL_': 'B@RCODE-1_4',\n",
    "    'G210_D_': 'B@RCODE-1_11',\n",
    "    'G150_D_': 'B@RCODE-1_7',\n",
    "    'G171_D_': 'B@RCODE-1_9',\n",
    "    'G120_D_FL_': 'B@RCODE-1_3',\n",
    "    'G187_D_': 'B@RCODE-1_10',\n",
    "    'G159_D_': 'B@RCODE-1_8',\n",
    "    'G129_D_': 'B@RCODE-1_6',\n",
    "    'G133_N_FL_': 'B@RCODE-1_5',\n",
    "    'G120_D_TL_': 'B@RCODE-1_2'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021d87-5b54-4856-8911-bd3b4ca68eed",
   "metadata": {},
   "source": [
    "**Review any IDs not mapped**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd27e6-7b10-4ce8-91de-dbe77fceb545",
   "metadata": {},
   "outputs": [],
   "source": [
    "[a for a in index_patterns if a not in id_map.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d10c900-acdc-46a3-a872-2626301b7c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[a for a in file_ids if a not in id_map.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5910f997-0238-4693-b5d0-d0f467f1f028",
   "metadata": {},
   "source": [
    "**Create a new fragments file for each raw file, amending barcodes and filtering some out**\\\n",
    "*This will also report statistics to review for QA of mappings*\\\n",
    "*May need to alter how `frag_file` is defined based on the file structure & naming*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe8d339-827d-408a-b00e-9d763e46a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_frag_files = []\n",
    "stats = []\n",
    "for s,a in id_map.items():\n",
    "    print(s)\n",
    "    frag_file = f'{my_dir}{s}{file_end}'\n",
    "\n",
    "    #read in the fragments\n",
    "    frags_df = pd.read_csv(\n",
    "        frag_file,\n",
    "        comment='#',\n",
    "        sep='\\t',\n",
    "        names=['chrom','start','end','barcode','readSupport']\n",
    "    )\n",
    "\n",
    "    #plot for QA\n",
    "    counts = frags_df['barcode'].value_counts()\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].hist(counts, range=(0,1000), bins=200)\n",
    "    axes[0].set_ylim(ymin=0)\n",
    "    axes[0].set_title('raw')\n",
    "\n",
    "    #store stats for QA\n",
    "    raw_min = counts.min()\n",
    "    raw_mean = round(counts.mean())\n",
    "\n",
    "    #update the barcode to match the CxG matrix obx index\n",
    "    frags_df['barcode'] = frags_df['barcode'].apply(lambda x: re.sub(replace_with, re.search(barcode_pattern, x).group(), a))\n",
    "\n",
    "    #filter down to only barcodes in the CxG matrix\n",
    "    frags_df = frags_df[frags_df['barcode'].isin(barcodes)]\n",
    "\n",
    "    #plot for QA\n",
    "    counts = frags_df['barcode'].value_counts()\n",
    "    axes[1].hist(counts, range=(0,1000), bins=200)\n",
    "    axes[1].set_ylim(ymin=0)\n",
    "    axes[1].set_title('filtered')\n",
    "    plt.show()\n",
    "\n",
    "    #store stats for QA\n",
    "    stats.append({\n",
    "        'sample': s,\n",
    "        'raw min': raw_min,\n",
    "        'filt min': counts.min(),\n",
    "        'raw mean': raw_mean,\n",
    "        'filt mean': round(counts.mean()),\n",
    "        'unique barcodes': len(counts)\n",
    "    })\n",
    "\n",
    "    #write the filtered fragments file\n",
    "    output = frag_file.replace(file_end, 'filtered_fragments.tsv')\n",
    "    frags_df.to_csv(output, sep='\\t', index=False, header=False)\n",
    "    ind_frag_files.append(output)\n",
    "\n",
    "pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de396f61-55b7-41c5-8b7d-1fd70e88e181",
   "metadata": {},
   "source": [
    "**Concatenate all of the outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4825be3e-1079-43a6-814a-e84df4bb40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = []\n",
    "for f in ind_frag_files:\n",
    "    p = subprocess.Popen(['gzip',f])\n",
    "    processes.append(p)\n",
    "\n",
    "for p in processes:\n",
    "    p.wait()\n",
    "\n",
    "ind_frag_files_gz = [f + '.gz' for f in ind_frag_files]\n",
    "concat_frags = f'{my_dir}concatenated_filtered_fragments.tsv.gz'\n",
    "subprocess.run(['cat ' + ' '.join(ind_frag_files_gz) + ' > ' + concat_frags], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c02012f-707d-4843-98b1-b86618e9b9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
