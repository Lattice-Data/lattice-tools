{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook provides code samples to be used to manipulate AnnData objects towards CELLxGENE curation\\\n",
    "It is not intended to be used as a single coherent workflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* **CELLxGENE Revision**\n",
    " * [Remove CELLxGENE portal fields](#revision)\n",
    "* **Matrix**\n",
    " * [Convert matrix to sparse](#sparsity)\n",
    " * [Convert raw matrix to sparse](#sparsity-raw)\n",
    " * [Subset the matrix](#subset)\n",
    "* **obsm**\n",
    " * [Convert x,y columns to embeddings](#set-embed)\n",
    "* **layers**\n",
    " * [Move a layer](#mv-layer)\n",
    " * [Delete a layer](#del-layer)\n",
    "* **uns**\n",
    " * [Set a field](#set-uns)\n",
    " * [Delete a field](#del-uns)\n",
    "* **obs**\n",
    " * [Remove columns](#del-obs)\n",
    " * [Rename columns](#rn-obs)\n",
    " * [Replace values](#rp-obs)\n",
    " * [Set a column with the same value](#set-obs)\n",
    " * [Fill null values in a specific column](#fillna-obs)\n",
    " * [Convert numeric field to categorical](#cat-obs)\n",
    " * [Alter the values in a column using a function](#typo-obs)\n",
    " * [Map HsapDv terms from human ages in specific years](#yr-hsapdv)\n",
    " * [Add a column mapped from another - dictionary](#add-dict-obs)\n",
    " * [Add a column mapped from aonther - Google Sheet](#add-gs-obs)\n",
    " * [Create a csv from barcode list](#create-csv)\n",
    "* **var**\n",
    " * [Remove columns](#del-var)\n",
    " * [Set a column with the same value](#set-var)\n",
    " * [Add a column mapped from another - function](#typo-var)\n",
    " * [Set a column as the index](#index-var)\n",
    " * [Map in Ensembl IDs based on symbols and reference annotation](#id-map-var)\n",
    " * [Curate raw.var](#raw-var)\n",
    " * [Fill var with filtered features that are in raw.var](#fill-filt-var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revising existing CELLxGENE Dataset <a class=\"anchor\" id=\"revision\"></a>\n",
    "**Remove fields that filled in by the portal upon submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portal_obs = [\n",
    "    'assay',\n",
    "    'cell_type',\n",
    "    'development_stage',\n",
    "    'disease',\n",
    "    'self_reported_ethnicity',\n",
    "    'organism',\n",
    "    'sex',\n",
    "    'tissue'\n",
    "]\n",
    "\n",
    "portal_var = [\n",
    "    'feature_name',\n",
    "    'feature_reference',\n",
    "    'feature_biotype'\n",
    "]\n",
    "\n",
    "portal_uns = [\n",
    "    'schema_version'\n",
    "]\n",
    "\n",
    "adata.obs.drop(columns=portal_obs, inplace=True)\n",
    "adata.var.drop(columns=portal_var, inplace=True)\n",
    "\n",
    "for p in portal_uns:\n",
    "    del adata.uns[p]\n",
    "\n",
    "if adata.raw:\n",
    "    adata.raw.var.drop(columns=portal_var, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert a matrix to sparse** <a class=\"anchor\" id=\"sparsity\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X = sparse.csr_matrix(adata.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert a matrix to sparse - raw layer** <a class=\"anchor\" id=\"sparsity-raw\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_adata = ad.AnnData(sparse.csr_matrix(adata.raw.X), var=adata.raw.var, obs=adata.obs)\n",
    "adata.raw = raw_adata\n",
    "del raw_adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subset a matrix for select observations** <a class=\"anchor\" id=\"subset\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_file = 'HumanNonNeuronal_clusterfile.txt'\n",
    "embed_df = pd.read_csv(embed_file, sep='\\t', skiprows=[1])\n",
    "obs_to_keep = embed_df['NAME']\n",
    "\n",
    "adatasm = adata[obs_to_keep, : ]\n",
    "adatasm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add spatial embeddings based on two columns in obs** <a class=\"anchor\" id=\"set-embed\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm['X_spatial'] = adata.obs[['xcoord','ycoord']].to_numpy()\n",
    "adata.obs.drop(columns=['xcoord','ycoord'], inplace=True)\n",
    "sc.pl.embedding(adata, basis='X_spatial', color=['cell_type_ontology_term_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Move a layer to the raw slot** <a class=\"anchor\" id=\"mv-layer\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_adata = ad.AnnData(adata.layers['counts'], dtype=adata.layers['counts'].dtype, var=adata.var)\n",
    "adata.raw = raw_adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete a layer** <a class=\"anchor\" id=\"del-layer\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata.layers['counts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# uns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a field in uns** <a class=\"anchor\" id=\"set-uns\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['default_embedding'] = 'X_umap'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove a field from uns** <a class=\"anchor\" id=\"del-uns\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata.uns['X_normalization']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove columns**  <a class=\"anchor\" id=\"del-obs\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_remove = [\n",
    "    'author_tissue',\n",
    "    'Assay',\n",
    "    'method',\n",
    "    'donor_age'\n",
    "]\n",
    "\n",
    "obs_remove = [o for o in obs_remove if o in adata.obs.columns]\n",
    "adata.obs.drop(columns=obs_remove, inplace=True)\n",
    "if obs_remove:\n",
    "    print('removed: ' + ','.join(obs_remove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change column names**  <a class=\"anchor\" id=\"rn-obs\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_me = {\n",
    "    'cell_type': 'author_cell_type',\n",
    "    'ethnicity_ontology_id': 'self_reported_ethnicity_ontology_term_id',\n",
    "    'disease_ontology_id': 'disease_ontology_term_id'\n",
    "}\n",
    "\n",
    "adata.obs.rename(columns=rename_me, inplace=True)\n",
    "adata.obs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace specified values in specified columns** <a class=\"anchor\" id=\"rp-obs\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_me = {\n",
    "    'organism_ontology_term_id':{'human': 'NCBITaxon:9606', 'mouse': 'NCBITaxon:10090'},\n",
    "    'assay_ontology_term_id': {'EFO:0030003': 'EFO:0009899'}\n",
    "}\n",
    "\n",
    "adata.obs.replace(replace_me,inplace=True)\n",
    "adata.obs[['organism_ontology_term_id','assay_ontology_term_id']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set a column with all the same values**  <a class=\"anchor\" id=\"set-obs\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['is_primary_data'] = True\n",
    "adata.obs['suspension_type'] = 'nucleus'\n",
    "adata.obs[['is_primary_data','suspension_type']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fill null values of a specific column with a specified value**  <a class=\"anchor\" id=\"fillna-obs\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'unknown' not in adata.obs['sex_ontology_term_id'].unique():\n",
    "    adata.obs['sex_ontology_term_id'] = adata.obs['sex_ontology_term_id'].cat.add_categories('unknown')\n",
    "adata.obs.fillna({'sex_ontology_term_id': 'unknown'}, inplace=True)\n",
    "adata.obs['sex_ontology_term_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update a gradient field to categorical** <a class=\"anchor\" id=\"cat-obs\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['cluster_id'] = adata.obs['cluster_id'].map(str)\n",
    "adata.obs['cluster_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adjust the values in a specific column in a standard way with a function** <a class=\"anchor\" id=\"typo-obs\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_typo(x):\n",
    "    return x.replace('_',':')\n",
    "\n",
    "\n",
    "adata.obs['development_stage_ontology_term_id'] = adata.obs['development_stage_ontology_term_id'].apply(fix_typo)\n",
    "adata.obs['development_stage_ontology_term_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use OLS to map HsapDv terms from human ages in specific years** <a class=\"anchor\" id=\"yr-hsapdv\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.ebi.ac.uk/ols4/api/ontologies/hsapdv/terms?size=500'\n",
    "r = requests.get(url).json()\n",
    "yr_specific = {t['label']: t['obo_id'] for t in r['_embedded']['terms'] if t['label'].endswith('-year-old human stage')}\n",
    "\n",
    "adata.obs['development_stage_ontology_term_id'] = adata.obs['age'].apply(lambda x: yr_specific[x + '-year-old human stage'])\n",
    "adata.obs[['age','development_stage_ontology_term_id']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add a new column mapped from another- with Dictionary** <a class=\"anchor\" id=\"add-dict-obs\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_map = {\n",
    "    'KL001': 'P21',\n",
    "    'KL002': 'P22',\n",
    "    'KL003': 'P23'\n",
    "}\n",
    "\n",
    "adata.obs['donor_id'] = adata.obs['sample'].map(donor_map)\n",
    "adata.obs[['donor_id','sample']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add a new column mapped from another - with Google Sheet** <a class=\"anchor\" id=\"add-gs-obs\"></a>\\\n",
    "**Step 1:** get the values to map from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in adata.obs['donor_id'].unique():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2** set up a dataframe with the mapping from a Google Sheet\\\n",
    "*Google Sheet permissions must be Anyone with Link is a Viewer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_id = '15oG8v5BS6HMPqCehYQcujMZUq9PgQNpo8osKhO7yA5o'\n",
    "tab_name = 'donor table'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={quote(tab_name)}'\n",
    "donor_meta = pd.read_csv(url)[['donor_id','sex_ontology_term_id','development_stage_ontology_term_id']]\n",
    "donor_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** merge the dataframe into obs\\\n",
    "*`how='left'` is critical to ensure obs order is retained\\\n",
    "`set_index` is critical to ensure the index is retained*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs = adata.obs.merge(donor_meta, on='donor_id',how='left').set_index(adata.obs.index)\n",
    "adata.obs[donor_meta.columns].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See what cell prefixes/suffixes are**\n",
    "<br>Note: This will need to be adapted depending on what the prefix/suffix looks like</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for prefix and suffix\n",
    "pattern = r\"[ACGT]*-1$\"  # for prefix\n",
    "#pattern = r\"^[AGCT]*\"  # for suffix\n",
    "adata_index_split = adata.obs.index.to_series().str.split(pat = pattern, regex=True, expand=True)\n",
    "adata_index_split.iloc[:,1].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create csv from barcode lists** <a class=\"anchor\" id=\"create-csv\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used in generating summary for 10x barcode csv table\n",
    "def summarize(v2,v3,m,b):\n",
    "    if re.match(r\".*[ACTG]{16}.*\", b):\n",
    "        if v2 + v3 + m > 1:\n",
    "            return 'multiple'\n",
    "        elif (v2 == 1) and (v3 == 0) and (m == 0):\n",
    "            return '3pv2_5pv1_5pv2'\n",
    "        elif (v2 == 0) and (v3 == 1) and (m == 0):\n",
    "            return '3pv3'\n",
    "        elif (v2 ==0 ) and (v3 == 0) and (m == 1):\n",
    "            return 'multiome'\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code in sample notebook consumes the barcodes across all 3 lists and compiles them into a table\n",
    "ref_dir = '../cellxgene_resources/ref_files/'\n",
    "v2_file = '737K-august-2016.txt'\n",
    "v3_file = '3M-february-2018.txt'\n",
    "multiome_file = '737K-arc-v1.txt'\n",
    "\n",
    "# create dataframes of ref files\n",
    "v2_df = pd.read_csv(ref_dir + v2_file, names=['barcode'])\n",
    "v2_df['3pv2_5pv1_5pv2'] = 1\n",
    "\n",
    "v3_df = pd.read_csv(ref_dir + v3_file, names=['barcode'])\n",
    "v3_df['3pv3'] = 1\n",
    "\n",
    "multiome_df = pd.read_csv(ref_dir + multiome_file, names=['barcode'])\n",
    "multiome_df['multiome'] = 1\n",
    "\n",
    "# merge ref dfs\n",
    "barcode_table_df = v2_df.merge(v3_df,on='barcode',how='outer').merge(multiome_df,on='barcode',how='outer')\n",
    "barcode_table_df.fillna(0, inplace=True)\n",
    "barcode_table['summary'] = barcode_table.apply(lambda x: summarize(x['3pv2_5pv1_5pv2'],x['3pv3'],x['multiome'],x['barcode']), axis=1)\n",
    "barcode_table_df.to_csv('10X_barcode_table.csv.gz', sep=',', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add summary column with the corresponding ref list \n",
    "for index,row in barcode_results_df.iterrows():\n",
    "    if (row[1]+row[2]+row[3]) > 1:\n",
    "        barcode_results_df.loc[index, 'summary'] = 'multiple'\n",
    "\n",
    "    elif (row[1]==1) and (row[2]==0) and (row[3]==0):\n",
    "        barcode_results_df.loc[index, 'summary'] = '3pv2_5pv1_5pv2' \n",
    "\n",
    "    elif (row[1]==0) and (row[2]==1) and (row[3]==0):\n",
    "        barcode_results_df.loc[index, 'summary'] = '3pv3'\n",
    "\n",
    "    elif (row[1]==0) and (row[2]==0) and (row[3]==1):\n",
    "        barcode_results_df.loc[index, 'summary'] = 'multiome'\n",
    "\n",
    "    else:\n",
    "        print('Error, check row conditions')\n",
    "\n",
    "# write barcode_results_df to csv for 10x barcode checker in curation_qa notebook\n",
    "barcode_results_df.to_csv('10X_barcode_results.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove columns** <a class=\"anchor\" id=\"del-var\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.drop(columns=['gene_symbols'], inplace=True)\n",
    "adata.var.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set a column with all the same values** <a class=\"anchor\" id=\"set-var\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var['feature_is_filtered'] = False\n",
    "adata.var['feature_is_filtered'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add a new column mapped from another - with function** <a class=\"anchor\" id=\"typo-var\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var['gene_id'] = adata.var['ensembl_version'].apply(lambda x: x.split('.')[0])\n",
    "adata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set a column as the index** <a class=\"anchor\" id=\"index-var\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.set_index('gene_id', inplace=True)\n",
    "adata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Map Ensembl IDs from symbols using a reference annotation** <a class=\"anchor\" id=\"id-map-var\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If CellRanger may have been used for alignment, check against the default CellRanger references for matches in order to inform symbol-to-ID mapping**<br>\n",
    "*Each tsv file has been compiled from the gtfs distributed with CellRanger and are stored in this repo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dir = 'ref_files/'\n",
    "CR_12 = 'refdata-cellranger-GRCh38-1_2_0_genes_gtf.tsv'\n",
    "CR_30 = 'refdata-cellranger-GRCh38-3_0_0_genes_gtf.tsv'\n",
    "CR_2020 = 'refdata-gex-GRCh38-2020-A_genes_gtf.tsv'\n",
    "CR_hg19 = 'refdata-cellranger-hg19-1_2_0_genes_gtf.tsv'\n",
    "results = []\n",
    "for v in [CR_12,CR_30,CR_2020,CR_hg19]:\n",
    "    map_df = pd.read_csv(ref_dir + v, sep='\\t')\n",
    "    results.append({\n",
    "        'ref': v,\n",
    "        'matched': adata.var.merge(map_df,left_index=True,right_on='gene_symbols',how='inner').shape[0]\n",
    "    })\n",
    "df = pd.DataFrame(results).set_index('ref')\n",
    "df['unmatched'] = df['matched'].apply(lambda x: adata.var.shape[0] - x)\n",
    "df.sort_values('unmatched', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If one of the CellRanger references looks like a good match, you can set it as the map file for use downstream, demonstrated further below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_mapping_file = ref_dir + CR_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IN PROGRESS: If a reference other than one of the default CellRanger reference files was used, a map file can be created from the annotation file for use in curation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If a GENCODE/ENSEMBL reference was used, parse the annotation file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts gene_id and gene_symbol from gtf\n",
    "\n",
    "def extract_gene_id_and_symb(dir, gtf):\n",
    "    '''\n",
    "    Input: path to gtf file\n",
    "    Output: dataframe of the gene_ids and gene_symbols\n",
    "    '''\n",
    "    gtf = pd.read_table(dir + gtf, header=None, comment = '#')\n",
    "    row_8 = gtf[8]\n",
    "    pattern1 = ';'\n",
    "    pattern2 = '(ENSG\\d{11})'\n",
    "    pattern3 = '([\\w\\d\\-]+)'\n",
    "    split1 = row_8.str.split(pattern1, expand=True)\n",
    "    gene_ids = split1[0].str.split(pattern2, expand=True)[1]\n",
    "    gene_sym = split1[4].str.split(pattern3, expand=True)[3]\n",
    "    gtf_df = pd.DataFrame({'gene_ids':gene_ids, 'gene_symbols':gene_sym})\n",
    "    gtf_df.drop_duplicates(inplace=True)  # drop rows where both gene_id and gene_symbol are duplicated\n",
    "    gtf_df.set_index('gene_ids')\n",
    "    return gtf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters out gene_symbols with multiple gene_ids and assigns 'multiple' as gene_id to corresponding gene_symbol\n",
    "def assign_multiple(gtf_df):\n",
    "    '''\n",
    "    Input: gtf pandas dataframe with gene_id and gene_symbol columns\n",
    "    Output: de-duplicated dataframe\n",
    "    '''\n",
    "    dups = gtf_df[gtf_df.duplicated(subset='gene_symbols',keep=False)]\n",
    "    dups['gene_ids'] = 'multiple'\n",
    "    dups = dups.drop_duplicates()  # only keep one instance of the gene_symbol\n",
    "    gene_df_wo_dups = gene_df.drop_duplicates(subset='gene_symbols',keep=False) \n",
    "    gene_df_multiple = gene_df_wo_dups.append(dups)  #create new df with all non-duplicated gene_symbols and gene_symbols with multiple ensembl ids\n",
    "    gene_df_multiple.set_index('gene_ids', inplace=True, )\n",
    "    return gene_df_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can include multiple gtf files (list of gtf files)\n",
    "gtf_list = ['gtf','gtf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and de-duplicate gene annotations and write them to a tsv file\n",
    "for file in gtf_list:\n",
    "    gtf_df = extract_gene_id_and_symb(file)\n",
    "    gene_id_symbol = assign_multiple(gtf_df)\n",
    "\n",
    "    # write dataframe to tsv file in ref_file folder\n",
    "    dir = '/path/to/cxg_curation/ref_files/'\n",
    "    tsv_file = file.replace('.','_') + '.tsv' \n",
    "    gene_id_symbol.to_csv(dir + tsv_file, sep= '\\t', compression= 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View what features are not mapped in this**<br>\n",
    "*Check for typos or other alterations to the symbols that can be fixed*<br>\n",
    "*Common to see many ending in `.1` or `-1` resulting from duplicated symbols in the reference*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_map_df = pd.read_csv(var_mapping_file, sep='\\t')\n",
    "adata.var[adata.var.index.isin(var_map_df['gene_symbols']) != True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Map the Ensembl IDs & set them to the index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var = adata.var.merge(var_map_df,left_index=True,right_on='gene_symbols',how='left').set_index(adata.var.index)\n",
    "adata.var.set_index('gene_ids', inplace=True)\n",
    "adata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter out genes that don't appear in the approved annotation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the list of approved IDs to filter on**<br>\n",
    "*For the initial run, download the 4 genes_ csv files from https://github.com/chanzuckerberg/single-cell-curation/tree/main/cellxgene_schema_cli/cellxgene_schema/ontology_files*<br>\n",
    "*After that, if the `genes_approved.csv` is available locally, then the 4 genes_ files won't be necessary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dir = 'ref_files/'\n",
    "ref_files = [\n",
    "    'genes_ercc.csv',\n",
    "    'genes_homo_sapiens.csv',\n",
    "    'genes_mus_musculus.csv',\n",
    "    'genes_sars_cov_2.csv'\n",
    "]\n",
    "\n",
    "if not os.path.exists(ref_dir + 'genes_approved.csv'):\n",
    "    ids = pd.DataFrame()\n",
    "    for f in ref_files:\n",
    "        df = pd.read_csv(ref_dir + f, names=['feature_id','symb','num','length'],dtype='str',index_col=False)\n",
    "        ids = ids.append(df)\n",
    "        os.remove(f)\n",
    "    ids.to_csv(ref_dir + 'genes_approved.csv', index=False)\n",
    "\n",
    "approved = pd.read_csv(ref_dir + 'genes_approved.csv',dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.reset_index(inplace=True)\n",
    "var_to_keep = adata.var[adata.var['gene_ids'].isin(approved['feature_id'])].index\n",
    "adata = adata[:, var_to_keep]\n",
    "adata.var.set_index('gene_ids', inplace=True)\n",
    "adata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeat much of the same steps for the `raw.var`, if it exists** <a class=\"anchor\" id=\"raw-var\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_adata = ad.AnnData(adata.raw.X, var=adata.raw.var, obs=adata.obs)\n",
    "\n",
    "raw_adata.var = raw_adata.var.merge(var_map_df,left_index=True,right_on='gene_symbols',how='left').set_index(raw_adata.var.index)\n",
    "\n",
    "raw_adata.var.reset_index(inplace=True)\n",
    "var_to_keep = raw_adata.var[raw_adata.var['gene_ids'].isin(approved['feature_id'])].index\n",
    "raw_adata = raw_adata[:, var_to_keep]\n",
    "raw_adata.var.set_index('gene_ids', inplace=True)\n",
    "\n",
    "adata.raw = raw_adata\n",
    "adata.raw.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fill genes that are present in raw but not in X** <a class=\"anchor\" id=\"fill-filt-var\"></a><br>\n",
    "*Ensure the matrix is CSR-formatted prior to using this*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_add = [e for e in adata.raw.var.index if e not in adata.var.index]\n",
    "new_matrix = sparse.csr_matrix((adata.X.data, adata.X.indices, adata.X.indptr), shape = adata.raw.shape)\n",
    "all_genes = adata.var.index.to_list()\n",
    "all_genes.extend(genes_add)\n",
    "new_var = pd.DataFrame(index=all_genes)\n",
    "new_var = pd.merge(new_var, adata.var, left_index=True, right_index=True, how='left')\n",
    "new_var.loc[genes_add, 'feature_is_filtered'] = True\n",
    "new_adata = ad.AnnData(X=new_matrix, dtype=new_matrix.dtype, obs=adata.obs, var=new_var, uns=adata.uns, obsm=adata.obsm, raw = adata.raw)\n",
    "new_adata = new_adata[:,adata.raw.var.index.to_list()]\n",
    "new_adata.var.loc[adata.var.index, 'feature_is_filtered'] = False\n",
    "new_adata.var['feature_is_filtered'] = new_adata.var['feature_is_filtered'].astype('bool')\n",
    "\n",
    "adata = new_adata\n",
    "\n",
    "adata.var['feature_is_filtered'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
